Transform articles into kids‚Äô audiobooks and comics with Telegram, BrowserAct, Gemini and ElevenLabs

https://n8nworkflows.xyz/workflows/transform-articles-into-kids--audiobooks-and-comics-with-telegram--browseract--gemini-and-elevenlabs-12365


# Transform articles into kids‚Äô audiobooks and comics with Telegram, BrowserAct, Gemini and ElevenLabs

## 1. Workflow Overview

**Purpose:** This workflow turns an online article/story link sent via **Telegram** into (1) a **rewritten children‚Äôs story**, (2) an **audiobook narration** generated by **ElevenLabs**, and (3) **comic-book style images** generated via **Gemini ‚ÄúNano Banana Pro‚Äù**. If the user does not send a link, the workflow falls back to chat and/or asks for a URL.

**Primary use cases:**
- Parents/educators sharing a web link to instantly receive kid-friendly story content with audio + visuals.
- A Telegram channel content pipeline for publishing story audio and illustrated comic pages.

### 1.1 Input Reception & Classification (Telegram ‚Üí LLM parser ‚Üí Switch)
Receives Telegram messages, classifies whether they contain a valid URL for article processing, and routes execution accordingly.

### 1.2 Article Scraping (BrowserAct)
If a link is present, calls a BrowserAct workflow/template to scrape and return the webpage‚Äôs story/article content as machine-readable output.

### 1.3 Narrative & Prompt Generation (LLM JSON output)
Cleans noisy scraped text, rewrites it into a long children‚Äôs story, generates 1‚Äì3 comic page prompts, prepares an HTML Telegram caption, and an audio filename.

### 1.4 Multimedia Production & Delivery (ElevenLabs + Gemini Image ‚Üí Telegram)
Generates audio from the story, sends it to Telegram, then iterates through prompts to generate and send comic images, rate-limiting between sends.

### 1.5 Conversational Fallback (No link / Chat)
If the message is chat or missing a link, generates a plain-text response prompting for a URL or replying conversationally.

---

## 2. Block-by-Block Analysis

### Block A ‚Äî Input Validation & Routing

**Overview:** Receives a Telegram message, uses an LLM to classify it into `Article_Request`, `Chat`, or `NoData`, then routes the flow to scraping or to a conversational fallback.

**Nodes involved:**
- **User Sends Message to Bot** (Telegram Trigger)
- **Validate user Input** (LangChain Agent)
- **Google Gemini** (Gemini chat model)
- **Structured Output Parser** (Structured JSON parser)
- **Check For Input Type** (Switch)
- **Process Initialization Alert** (Telegram send message)

#### Node: User Sends Message to Bot
- **Type / role:** `telegramTrigger` ‚Äî workflow entry point; listens for incoming Telegram messages.
- **Configuration:** Watches `message` updates.
- **Outputs:** Emits Telegram update payload including `message.text` and `message.chat.id`.
- **Failure modes / edge cases:**
  - Telegram credential errors (bot token invalid/revoked).
  - Bot privacy settings: bot may not receive messages in groups unless configured.
  - Non-text messages (photos/voice) will not have `message.text` (classification may fail unless handled).

#### Node: Validate user Input
- **Type / role:** `@n8n/n8n-nodes-langchain.agent` ‚Äî classifies user text into a strict JSON object.
- **Key input mapping:** `text = {{ $json.message.text }}`
- **System message logic (interpreted):**
  - If user asks to process an article/story AND includes a valid URL ‚Üí `{"Type":"Article_Request","Link":"..."}`.
  - If greeting/small talk without link processing ‚Üí `{"Type":"Chat","Link":"Null"}`.
  - If missing link or insufficient data ‚Üí `{"Type":"NoData","Link":"Null"}`
- **Connections:**
  - Uses **Google Gemini** as the language model (AI input).
  - Uses **Structured Output Parser** as the output parser (forces JSON schema).
  - Main output goes to **Check For Input Type**.
- **Failure modes / edge cases:**
  - If `message.text` is undefined (non-text messages), the agent may output malformed/empty content.
  - Misclassification if user includes malformed URLs or multiple URLs.
  - Model may output invalid JSON; mitigated by output parser `autoFix=true`.

#### Node: Google Gemini
- **Type / role:** `lmChatGoogleGemini` ‚Äî LLM backend for input classification.
- **Credentials:** Google Gemini (PaLM) API.
- **Failure modes:**
  - API quota/rate limits, invalid API key, region restrictions.

#### Node: Structured Output Parser
- **Type / role:** Structured output parser enforcing a JSON schema for the classifier.
- **Schema example:** `{"Type":"Article_Request","Link":"extracted_link"}`
- **Setting:** `autoFix=true` to repair minor formatting errors.
- **Connections:** Attached as `ai_outputParser` to **Validate user Input**.
- **Failure modes:**
  - If model output is too far from JSON, auto-fix may still fail.

#### Node: Check For Input Type
- **Type / role:** `switch` ‚Äî routes by `{{$json.output.Type}}`.
- **Rules:**
  1. If equals `Article_Request` ‚Üí branch 1
  2. If equals `Chat` ‚Üí branch 2
  3. If equals `NoData` ‚Üí branch 3
- **Outputs:**
  - **Article_Request:** goes to **Process Initialization Alert** and **Get Story via BrowserAct** (two parallel outgoing connections).
  - **Chat/NoData:** both go to **Chatting With User**.
- **Failure modes:**
  - If `output.Type` missing due to upstream parsing failure, no rule matches (workflow stops or goes to ‚Äúno match‚Äù behavior depending on n8n settings).

#### Node: Process Initialization Alert
- **Type / role:** `telegram` (send message) ‚Äî informs the user processing started.
- **Text:** ‚ÄúOk, I will do it please give me a moment.‚Äù
- **Chat ID expression:** Uses the trigger‚Äôs chat id via an expression-like field (the stored value appears non-standard in JSON, but intent is: `{{ $('User Sends Message to Bot').item.json.message.chat.id }}`).
- **Failure modes:**
  - Incorrect chatId expression causes Telegram ‚Äúchat not found‚Äù.
  - If used in channels, you must use channel ID (negative ID format).

**Sticky note coverage:**  
- ‚Äú### ü§ñ Step 1: Input Validation & Scraping ‚Ä¶‚Äù (applies to this block and scraping block)

---

### Block B ‚Äî Scraping / Retrieval via BrowserAct

**Overview:** Calls a BrowserAct workflow/template to fetch and extract story/article data from the provided URL.

**Nodes involved:**
- **Get Story via BrowserAct**

#### Node: Get Story via BrowserAct
- **Type / role:** `n8n-nodes-browseract.browserAct` ‚Äî executes a BrowserAct workflow.
- **Mode:** `type=WORKFLOW`
- **Timeout:** 7200 seconds (2 hours), suitable for heavier browser automations.
- **Workflow ID:** `69908776368243698`
- **Input mapping:** `Target_link = {{ $json.output.Link }}`
- **Connections:** Output goes to **Summarize the Story**.
- **Failure modes / edge cases:**
  - BrowserAct credential invalid or workflow/template missing.
  - Target site blocks automation (Cloudflare, paywalls, login walls).
  - Page renders slowly ‚Üí may hit BrowserAct internal limits even if n8n timeout is high.
  - Output shape mismatch: downstream node expects `{{$json.output.string}}` to exist.

**Sticky note coverage:**  
- ‚Äú### ü§ñ Step 1: Input Validation & Scraping ‚Ä¶‚Äù (includes BrowserAct scraping)

---

### Block C ‚Äî Narrative Cleaning + Story/Prompts/Metadata Generation

**Overview:** Takes scraped ‚Äúraw messy JSON/text fragments‚Äù, removes noise/duplicates, rewrites a complete children‚Äôs story, generates comic prompts, creates an HTML caption, and an audio filename.

**Nodes involved:**
- **OpenRouter**
- **Structured Output**
- **Summarize the Story**

#### Node: OpenRouter
- **Type / role:** `lmChatOpenRouter` ‚Äî LLM backend for the main creative generation.
- **Model:** `google/gemini-3-pro-preview`
- **Credentials:** OpenRouter API.
- **Connections:** Provides the `ai_languageModel` input to **Summarize the Story** and **Structured Output** (as configured).
- **Failure modes:**
  - OpenRouter API key invalid, provider/model unavailable, rate limits, higher latency.

#### Node: Structured Output
- **Type / role:** Structured output parser for the main creative JSON result.
- **Schema fields:**
  - `comic_book_prompts` (array of 1‚Äì3 strings)
  - `full_story_text` (long story)
  - `telegram_caption` (HTML string)
  - `audio_filename` (snake_case `.mp3`)
- **Setting:** `autoFix=true`
- **Connections:** Attached to **Summarize the Story** as `ai_outputParser`.
- **Failure modes:**
  - Caption may exceed Telegram limits (~1024 chars) if the model ignores constraints.
  - JSON may be invalid if the model returns unescaped newlines/quotes; autoFix may not fully repair.

#### Node: Summarize the Story
- **Type / role:** `@n8n/n8n-nodes-langchain.agent` ‚Äî despite the name, it is instructed **not to summarize**, but to fully rewrite and structure output.
- **Input text:** `Article or Story Data : {{ $json.output.string }}`
- **System message highlights (interpreted):**
  - Deduplicate & filter noise (ads/nav/system commands).
  - Stitch coherent narrative timeline.
  - Produce 1‚Äì3 comic prompts (each prompt describes a single page with 4‚Äì6 panels, ‚ÄúWestern comic/graphic novel style‚Äù).
  - Produce long-form children‚Äôs retelling (age 4‚Äì9).
  - Produce Telegram HTML caption incl. ‚ÄúDiscussion Starter‚Äù if found.
  - Produce snake_case audio filename.
- **Outputs / connections:**
  - Main output branches to:
    - **Generate Story Audio**
    - **Split Image Prompts**
- **Failure modes / edge cases:**
  - If BrowserAct output doesn‚Äôt include `output.string`, the prompt becomes empty ‚Üí weak/failed generation.
  - If the scraped content is extremely long, LLM context limits may truncate or fail.
  - Safety filters could refuse certain content; handle by messaging user.

**Sticky note coverage:**  
- ‚Äú### ‚úçÔ∏è Step 2: Narrative & Visual Architecture ‚Ä¶‚Äù (applies to this block)

---

### Block D ‚Äî Audio Production & Telegram Delivery (Audio)

**Overview:** Converts the generated story text to speech using ElevenLabs and sends the audio file to Telegram with the generated caption and filename.

**Nodes involved:**
- **Generate Story Audio**
- **Send an audio file To User**
- **Workflow Completion Notification** (partially; completion is after images loop)

#### Node: Generate Story Audio
- **Type / role:** `@elevenlabs/n8n-nodes-elevenlabs.elevenLabs` ‚Äî text-to-speech.
- **Resource:** `speech`
- **Text input:** `{{ $json.output.full_story_text }}`
- **Voice:** ‚ÄúLiam - Energetic, Social Media Creator‚Äù (voice id `TX3LPaxmHKxFdv7VOQHJ`)
- **Model:** `eleven_flash_v2_5`
- **Language:** `en`
- **Output:** Binary audio data (used by Telegram sendAudio node).
- **Failure modes / edge cases:**
  - ElevenLabs quota exceeded / rate limiting.
  - Very long text may exceed allowed character limits for the selected model.
  - Output binary property naming: Telegram node expects `binaryData=true` and default binary field; mismatch can break sending.

#### Node: Send an audio file To User
- **Type / role:** `telegram` ‚Äî sends audio (`sendAudio`) to a Telegram chat/channel.
- **ChatId:** Hardcoded placeholder `"Your Telegram Channel ID"` (must be replaced).
- **Binary:** `binaryData=true`
- **Caption:** `{{ $('Summarize the Story').first().json.output.telegram_caption }}`
- **File name:** `{{ $('Summarize the Story').first().json.output.audio_filename }}`
- **Parse mode:** HTML
- **Failure modes / edge cases:**
  - If chatId remains the placeholder string, sending will fail.
  - Caption HTML may be invalid ‚Üí Telegram rejects or renders incorrectly.
  - If audio binary is missing/empty, Telegram API fails.

**Sticky note coverage:**  
- ‚Äú### üéôÔ∏è Step 3: Multimedia Production and Final Delivery ‚Ä¶‚Äù (applies to this and image branch)

---

### Block E ‚Äî Comic Image Production, Iteration, Rate Limiting, Delivery

**Overview:** Splits the prompt array into items, loops to generate an image per prompt via Gemini image model, sends each image to Telegram, waits to avoid rate limits, and repeats until done. Sends a completion message.

**Nodes involved:**
- **Split Image Prompts**
- **Loop Over Items**
- **Generate Strory image**
- **Send Story Comic Images**
- **Avoid Rate Limits**
- **Workflow Completion Notification**

#### Node: Split Image Prompts
- **Type / role:** `splitOut` ‚Äî converts `output.comic_book_prompts` array into one item per prompt.
- **Field to split:** `output.comic_book_prompts`
- **Output:** Each item represents one prompt string (kept under the same item JSON structure).
- **Failure modes:**
  - If `output.comic_book_prompts` missing or not an array ‚Üí node errors or outputs nothing.

#### Node: Loop Over Items
- **Type / role:** `splitInBatches` ‚Äî batch/loop controller.
- **Configuration:** default options (batch size defaults apply).
- **Connections:**
  - Output 0 ‚Üí **Workflow Completion Notification** (this is likely intended as the ‚Äúno more items‚Äù/done branch depending on n8n behavior and wiring).
  - Output 1 ‚Üí **Generate Strory image**
- **Edge cases:**
  - Miswiring can cause the completion message to be sent too early or repeatedly. Verify which output is ‚Äúdone‚Äù vs ‚Äúcontinue‚Äù in your n8n version.

#### Node: Generate Strory image
- **Type / role:** `@n8n/n8n-nodes-langchain.googleGemini` (Gemini Image) ‚Äî generates an image from a prompt.
- **Model:** `models/gemini-3-pro-image-preview` (labeled ‚ÄúNano Banana Pro‚Äù)
- **Prompt:** `{{ $json["output.comic_book_prompts"] }}`  
  - Note: after splitting, you often want the *current prompt string*; depending on `splitOut` output shape, you may need `{{ $json.output.comic_book_prompts }}` or `{{ $json.value }}`. As written, it assumes the field still exists with that key.
- **Binary output property:** `data`
- **Connections:** to **Send Story Comic Images**
- **Failure modes / edge cases:**
  - If prompt expression points to a missing field, Gemini will receive empty prompt.
  - API rate limits and content policy refusals.
  - Large images may exceed Telegram constraints if not compressed.

#### Node: Send Story Comic Images
- **Type / role:** `telegram` ‚Äî sends a photo (`sendPhoto`) using binary.
- **ChatId:** Hardcoded placeholder `"Your Telegram Channel ID"` (must be replaced).
- **Binary:** `binaryData=true` (expects the image binary from previous node)
- **Connections:** to **Avoid Rate Limits**
- **Failure modes:**
  - Placeholder chatId not replaced.
  - Telegram requires the correct binary property; if Gemini outputs to `data`, ensure Telegram node is configured to use that binary property (otherwise it may look for `data` vs default `data` handling depending on node settings).

#### Node: Avoid Rate Limits
- **Type / role:** `wait` ‚Äî pauses between image sends.
- **Configuration:** not explicitly set (defaults apply; likely manual/default wait behavior).
- **Connections:** to **Loop Over Items**
- **Failure modes:**
  - If wait is too short, Telegram/Gemini may still rate-limit.
  - If wait is misconfigured (very long), workflow will appear ‚Äústuck‚Äù.

#### Node: Workflow Completion Notification
- **Type / role:** `telegram` ‚Äî sends ‚ÄúStory Generation Complete.‚Äù
- **Chat ID expression:** Intended to use the trigger‚Äôs `message.chat.id` (same caveat as other Telegram message nodes).
- **Execute once:** `true` (prevents repeated sends in a single execution).
- **Failure modes:**
  - If loop wiring causes premature ‚Äúdone‚Äù, the completion message may fire before images finish.
  - Chat ID expression errors.

**Sticky note coverage:**  
- ‚Äú### üéôÔ∏è Step 3: Multimedia Production and Final Delivery ‚Ä¶‚Äù (covers this whole block)

---

### Block F ‚Äî Conversational Fallback (Chat / NoData)

**Overview:** If the user didn‚Äôt provide a link or is just chatting, responds with a single plain-text message. If `NoData`, it prompts the user to provide a URL.

**Nodes involved:**
- **Google Gemini1**
- **Chatting With User**
- **Answer the User**

#### Node: Google Gemini1
- **Type / role:** `lmChatGoogleGemini` ‚Äî LLM backend for fallback conversation.
- **Credentials:** Gemini (PaLM).
- **Connection:** provides `ai_languageModel` to **Chatting With User**.
- **Failure modes:** Same as other Gemini LLM node (quota/auth).

#### Node: Chatting With User
- **Type / role:** `@n8n/n8n-nodes-langchain.agent` ‚Äî generates raw text response.
- **Input text:** `Input type : {{ $json.output.Type }} | User Input : {{ $('User Sends Message to Bot').item.json.message.text }}`
- **System behavior:**
  - If input type is ‚ÄúNodata‚Äù (note: casing mismatch vs `NoData` in switch) ‚Üí ask for the link.
  - If type is chat ‚Üí respond conversationally.
  - Output must be raw text (no markdown fences).
- **Connections:** to **Answer the User**
- **Edge cases:**
  - The system instruction says `"Nodata"` but classifier emits `"NoData"` ‚Üí the agent might not trigger the ‚Äúask for link‚Äù behavior consistently unless it reasons around it.

#### Node: Answer the User
- **Type / role:** `telegram` ‚Äî sends a text message back to the user.
- **Text:** `{{ $json.output }}`
- **Chat ID expression:** Intended to reply to the original chat id (same caveat).
- **Parse mode:** HTML enabled, but the agent is asked to avoid tags; HTML mode may still be fine for plain text.
- **Failure modes:**
  - Wrong chat ID expression.
  - If agent returns overly long text, Telegram message length limits apply.

**Sticky note coverage:**  
- ‚Äú### üí¨ Step 2-2: Conversational Fallback ‚Ä¶‚Äù (applies to this block)

---

## 3. Summary Table

| Node Name | Node Type | Functional Role | Input Node(s) | Output Node(s) | Sticky Note |
|---|---|---|---|---|---|
| Documentation | Sticky Note | Human-facing overview & requirements |  |  | ## ‚ö° Workflow Overview & Setup / Requirements / How to Use / Links to BrowserAct docs |
| User Sends Message to Bot | Telegram Trigger | Entry point: receive Telegram messages |  | Validate user Input | ### ü§ñ Step 1: Input Validation & Scraping |
| Google Gemini | Gemini Chat Model | LLM for input classification |  | (AI) Validate user Input; (AI) Structured Output Parser | ### ü§ñ Step 1: Input Validation & Scraping |
| Structured Output Parser | Structured Output Parser | Enforce classifier JSON schema | Google Gemini (AI) | (AI) Validate user Input | ### ü§ñ Step 1: Input Validation & Scraping |
| Validate user Input | LangChain Agent | Classify input into Article_Request / Chat / NoData | User Sends Message to Bot | Check For Input Type | ### ü§ñ Step 1: Input Validation & Scraping |
| Check For Input Type | Switch | Route by `output.Type` | Validate user Input | (1) Process Initialization Alert + Get Story via BrowserAct; (2) Chatting With User; (3) Chatting With User | ### ü§ñ Step 1: Input Validation & Scraping |
| Process Initialization Alert | Telegram (send message) | Tell user processing started | Check For Input Type |  | ### ü§ñ Step 1: Input Validation & Scraping |
| Get Story via BrowserAct | BrowserAct | Scrape/extract article content from URL | Check For Input Type | Summarize the Story | ### ü§ñ Step 1: Input Validation & Scraping |
| OpenRouter | OpenRouter Chat Model | Main LLM for story/prompt JSON generation |  | (AI) Summarize the Story; (AI) Structured Output | ### ‚úçÔ∏è Step 2: Narrative & Visual Architecture |
| Structured Output | Structured Output Parser | Enforce story/prompt JSON schema | OpenRouter (AI) | (AI) Summarize the Story | ### ‚úçÔ∏è Step 2: Narrative & Visual Architecture |
| Summarize the Story | LangChain Agent | Clean scraped text; produce story, prompts, caption, filename | Get Story via BrowserAct | Generate Story Audio; Split Image Prompts | ### ‚úçÔ∏è Step 2: Narrative & Visual Architecture |
| Generate Story Audio | ElevenLabs | Text-to-speech audiobook generation | Summarize the Story | Send an audio file To User | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery |
| Send an audio file To User | Telegram (sendAudio) | Deliver audio + caption to Telegram channel/chat | Generate Story Audio |  | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery |
| Split Image Prompts | Split Out | Turn prompt array into items | Summarize the Story | Loop Over Items | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery |
| Loop Over Items | Split In Batches | Loop controller for per-prompt image generation | Split Image Prompts; Avoid Rate Limits | Workflow Completion Notification; Generate Strory image | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery |
| Generate Strory image | Gemini Image | Generate comic page image from prompt | Loop Over Items | Send Story Comic Images | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery |
| Send Story Comic Images | Telegram (sendPhoto) | Deliver each comic image to Telegram | Generate Strory image | Avoid Rate Limits | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery |
| Avoid Rate Limits | Wait | Pause between images to avoid API limits | Send Story Comic Images | Loop Over Items | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery |
| Workflow Completion Notification | Telegram (send message) | Notify completion | Loop Over Items |  | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery |
| Google Gemini1 | Gemini Chat Model | LLM for fallback conversation |  | (AI) Chatting With User | ### üí¨ Step 2-2: Conversational Fallback |
| Chatting With User | LangChain Agent | Chat response / ask for link (raw text) | Check For Input Type | Answer the User | ### üí¨ Step 2-2: Conversational Fallback |
| Answer the User | Telegram (send message) | Respond in Telegram to chat/nodata | Chatting With User |  | ### üí¨ Step 2-2: Conversational Fallback |
| Step 1 Explanation | Sticky Note | Human comment: validation + scraping |  |  | ### ü§ñ Step 1: Input Validation & Scraping (comment text) |
| Step 2 Explanation | Sticky Note | Human comment: narrative + prompts |  |  | ### ‚úçÔ∏è Step 2: Narrative & Visual Architecture (comment text) |
| Step 3 Explanation | Sticky Note | Human comment: audio + images |  |  | ### üéôÔ∏è Step 3: Multimedia Production and Final Delivery (comment text) |
| Step 4 Explanation | Sticky Note | Human comment: fallback conversation |  |  | ### üí¨ Step 2-2: Conversational Fallback (comment text) |

---

## 4. Reproducing the Workflow from Scratch

1) **Create Telegram Trigger**
   - Add **Telegram Trigger** node: *User Sends Message to Bot*
   - Updates: `message`
   - Connect Telegram credentials (Bot token).

2) **Add LLM for classification**
   - Add **Google Gemini Chat Model** node: *Google Gemini*
   - Configure credentials: Gemini (PaLM) API key.

3) **Add Structured Output Parser (classification)**
   - Add **Structured Output Parser** node: *Structured Output Parser*
   - Enable **Auto-fix**
   - Schema example: `{"Type":"Article_Request","Link":"extracted_link"}`

4) **Add LangChain Agent (classification)**
   - Add **AI Agent** node: *Validate user Input*
   - Input text: `{{ $json.message.text }}`
   - Set **System Message** to the classification rules (Article_Request with URL / Chat / NoData).
   - Attach:
     - Language Model: **Google Gemini**
     - Output Parser: **Structured Output Parser**
   - Connect: Telegram Trigger ‚Üí Validate user Input

5) **Add Switch router**
   - Add **Switch** node: *Check For Input Type*
   - Rule 1: `{{ $json.output.Type }}` equals `Article_Request`
   - Rule 2: equals `Chat`
   - Rule 3: equals `NoData`
   - Connect: Validate user Input ‚Üí Switch

6) **Add ‚Äúprocessing started‚Äù Telegram message**
   - Add **Telegram** node: *Process Initialization Alert* (operation: sendMessage)
   - Text: ‚ÄúOk, I will do it please give me a moment.‚Äù
   - Chat ID: set expression to the trigger chat id: `{{ $('User Sends Message to Bot').item.json.message.chat.id }}`
   - Connect from Switch output for `Article_Request` to this node.

7) **Add BrowserAct scraper**
   - Add **BrowserAct** node: *Get Story via BrowserAct*
   - Mode: WORKFLOW
   - Workflow ID: `69908776368243698`
   - Timeout: 7200
   - Map input `Target_link` to `{{ $json.output.Link }}`
   - Connect BrowserAct credentials.
   - Connect from Switch `Article_Request` output to BrowserAct.

8) **Add OpenRouter LLM (main generation)**
   - Add **OpenRouter Chat Model** node: *OpenRouter*
   - Model: `google/gemini-3-pro-preview`
   - Configure OpenRouter API credential.

9) **Add Structured Output Parser (story JSON)**
   - Add **Structured Output Parser** node: *Structured Output*
   - Auto-fix enabled
   - Schema example includes:
     - `comic_book_prompts` array
     - `full_story_text`
     - `telegram_caption` (HTML)
     - `audio_filename`

10) **Add LangChain Agent (story/prompt generation)**
   - Add **AI Agent** node: *Summarize the Story*
   - Text: `Article or Story Data : {{ $json.output.string }}`
   - System message: the ‚ÄúNarrative Architect and Visual Director‚Äù instruction set (cleaning + rewriting + prompts + caption + filename).
   - Attach:
     - Language Model: **OpenRouter**
     - Output Parser: **Structured Output**
   - Connect: BrowserAct ‚Üí Summarize the Story

11) **Audio branch (ElevenLabs)**
   - Add **ElevenLabs** node: *Generate Story Audio* (resource: speech)
   - Text: `{{ $json.output.full_story_text }}`
   - Choose voice (e.g., Liam) and model (`eleven_flash_v2_5`), language `en`
   - Configure ElevenLabs credential.
   - Connect: Summarize the Story ‚Üí Generate Story Audio

12) **Send audio to Telegram**
   - Add **Telegram** node: *Send an audio file To User* (operation: sendAudio)
   - chatId: replace with your actual target (user chat id or channel id). If replying to the requester, use: `{{ $('User Sends Message to Bot').item.json.message.chat.id }}`
   - Enable **Binary Data**
   - Caption: `{{ $('Summarize the Story').first().json.output.telegram_caption }}`
   - File name: `{{ $('Summarize the Story').first().json.output.audio_filename }}`
   - Parse mode: HTML
   - Connect: Generate Story Audio ‚Üí Send audio

13) **Image prompts split**
   - Add **Split Out** node: *Split Image Prompts*
   - Field to split: `output.comic_book_prompts`
   - Connect: Summarize the Story ‚Üí Split Image Prompts

14) **Loop controller**
   - Add **Split In Batches** node: *Loop Over Items*
   - Connect: Split Image Prompts ‚Üí Loop Over Items

15) **Gemini Image generation**
   - Add **Gemini Image** node: *Generate Strory image*
   - Model: `models/gemini-3-pro-image-preview`
   - Prompt: map to the current prompt item (verify after Split Out). Adjust expression as needed so it references the prompt string correctly.
   - Set binary output property to `data`.
   - Connect: Loop Over Items (continue branch) ‚Üí Generate Strory image

16) **Send image to Telegram**
   - Add **Telegram** node: *Send Story Comic Images* (operation: sendPhoto)
   - chatId: replace placeholder with actual chat/channel id (or expression to reply to the user)
   - Enable binary data and ensure it uses the same binary property produced by Gemini (`data`).
   - Connect: Generate Strory image ‚Üí Send Story Comic Images

17) **Wait / rate limiting**
   - Add **Wait** node: *Avoid Rate Limits*
   - Configure an appropriate delay (e.g., a few seconds) to avoid Telegram/Gemini rate limits.
   - Connect: Send Story Comic Images ‚Üí Wait ‚Üí Loop Over Items (to continue loop)

18) **Completion notification**
   - Add **Telegram** node: *Workflow Completion Notification* (sendMessage)
   - Text: ‚ÄúStory Generation Complete.‚Äù
   - chatId: `{{ $('User Sends Message to Bot').item.json.message.chat.id }}`
   - Connect from Loop Over Items ‚Äúdone/no more items‚Äù output to this node.
   - Optionally set ‚ÄúExecute once‚Äù to avoid duplicates.

19) **Fallback conversation branch**
   - Add **Google Gemini Chat Model** node: *Google Gemini1*
   - Add **AI Agent** node: *Chatting With User*
     - Text: `Input type : {{ $json.output.Type }} | User Input : {{ $('User Sends Message to Bot').item.json.message.text }}`
     - System message: ask for link if NoData; otherwise reply conversationally; output raw text.
     - Attach language model: Google Gemini1
   - Add **Telegram** node: *Answer the User* (sendMessage)
     - Text: `{{ $json.output }}`
     - chatId: `{{ $('User Sends Message to Bot').item.json.message.chat.id }}`
   - Connect: Switch outputs (`Chat` and `NoData`) ‚Üí Chatting With User ‚Üí Answer the User

---

## 5. General Notes & Resources

| Note Content | Context or Link |
|---|---|
| **Workflow Overview & Setup** ‚Äî Converts online articles into children's audiobooks and multi-panel comic images delivered via Telegram. Requires credentials: Telegram, BrowserAct, OpenRouter, ElevenLabs, Google Gemini (PaLM). Mandatory: BrowserAct API Template ‚ÄúChildren‚Äôs Book Storytelling & Illustration‚Äù. | From sticky note ‚ÄúDocumentation‚Äù |
| How to Find Your BrowserAct API Key & Workflow ID | https://docs.browseract.com |
| How to Connect n8n to BrowserAct | https://docs.browseract.com |
| How to Use & Customize BrowserAct Templates | https://docs.browseract.com |