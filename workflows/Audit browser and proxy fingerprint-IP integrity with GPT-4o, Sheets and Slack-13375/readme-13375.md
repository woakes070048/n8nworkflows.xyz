Audit browser and proxy fingerprint/IP integrity with GPT-4o, Sheets and Slack

https://n8nworkflows.xyz/workflows/audit-browser-and-proxy-fingerprint-ip-integrity-with-gpt-4o--sheets-and-slack-13375


# Audit browser and proxy fingerprint/IP integrity with GPT-4o, Sheets and Slack

## 1. Workflow Overview

**Title:** Audit browser and proxy fingerprint/IP integrity with GPT-4o, Sheets and Slack  
**Workflow name (internal):** Audit browser fingerprint and IP integrity to Slack reports  
**Purpose:** Automatically test multiple â€œbot-detection / IP reputation / fingerprintâ€ websites using BrowserAct, have GPTâ€‘4o analyze the raw outputs for bot-detection signals and inconsistencies, store each per-site diagnostic in Google Sheets, then produce a consolidated â€œGO / NOâ€‘GOâ€ security verdict and post it to Slack.

### 1.1 Trigger & Data Reset
Starts manually, then clears the Google Sheet â€œdatabaseâ€ to store fresh run results.

### 1.2 Target URL Definition & Iteration
Defines a list of test URLs, splits them into individual items, and loops over them in batches.

### 1.3 BrowserAct Collection (Two test tracks)
For each URL, executes BrowserAct workflows to fetch raw diagnostic outputs:
- A â€œguardedâ€ site accessibility check (fixed heavy-protected site)
- The regular â€œdetection siteâ€ checks (using the URL list)

### 1.4 AI Forensic Analysis (Per-site)
Each BrowserAct output is analyzed by a GPTâ€‘4o security analyst agent, producing a **structured JSON** with a single key `text` (markdown report).

### 1.5 Persistence (Google Sheets)
Appends each per-site report (`Result`) into a Google Sheet.

### 1.6 Aggregation, Final AI Verdict, Slack Delivery
Reads all stored results, aggregates them, has GPTâ€‘4o produce a final â€œGO / NOâ€‘GOâ€ summary, and posts it to a Slack channel.

---

## 2. Block-by-Block Analysis

### Block 1 â€” Trigger & Sheet Reset
**Overview:** Manually starts the workflow and clears the reporting sheet while preserving the header row. Ensures each run starts with an empty dataset.

**Nodes involved:**
- Execute manually
- Clear Database

#### Node: Execute manually
- **Type / role:** `Manual Trigger` â€” entry point for on-demand execution.
- **Configuration:** No parameters.
- **Outputs:** Sends a single trigger item to **Clear Database**.
- **Edge cases:** None (manual operation).

#### Node: Clear Database
- **Type / role:** `Google Sheets` â€” clears existing rows to reset run state.
- **Configuration (interpreted):**
  - Operation: **Clear**
  - Document: â€œIP, Fingerprint Integrity and Bot Detection Checkâ€ (Spreadsheet ID `1HFo...`)
  - Sheet/tab: â€œDataBaseâ€ (`gid=0`)
  - **keepFirstRow: true** (header preserved)
- **Credentials:** Google Sheets OAuth2 (â€œGoogle Sheets accountâ€).
- **Outputs:** Passes control to **Define Target URLs**.
- **Failure modes / edge cases:**
  - OAuth token expired / missing scopes â†’ auth errors.
  - Sheet renamed / gid changed â†’ â€œsheet not foundâ€.
  - If header row is not present, later â€œappendâ€ still works but your data model may drift.

---

### Block 2 â€” Define Targets & Loop Control
**Overview:** Creates the list of target detection URLs, converts it into one item per URL, then iterates over them using a batching loop.

**Nodes involved:**
- Define Target URLs
- Split Out
- Loop Over URLs

#### Node: Define Target URLs
- **Type / role:** `Set` â€” defines configuration data for the run.
- **Configuration:**
  - Creates field `urls` as an **array** expression:
    - `https://www.browserscan.net/bot-detection`
    - `https://www.ipqualityscore.com/free-ip-lookup-proxy-vpn-test`
    - `https://www.ip-score.com/`
  - Note: node comment says â€œDefine your 10 target sites here.â€ (currently 3).
- **Inputs:** From **Clear Database**.
- **Outputs:** To **Split Out**.
- **Edge cases:**
  - Invalid expression syntax breaks execution.
  - Empty list â†’ downstream BrowserAct nodes receive no URLs; loop may effectively do nothing.

#### Node: Split Out
- **Type / role:** `Split Out` â€” converts the `urls` array into individual items.
- **Configuration:** Field to split: `urls`.
- **Inputs:** From **Define Target URLs**.
- **Outputs:** To **Loop Over URLs**.
- **Edge cases:** If `urls` is not an array, the node will error.

#### Node: Loop Over URLs
- **Type / role:** `Split In Batches` â€” controls iteration over items.
- **Configuration:**
  - `reset: false` (does not reset automatically; relies on normal loop behavior).
  - Batch size uses node default (not explicitly set in JSON).
- **Inputs:** From **Split Out** and also loop-back from **Update Database**.
- **Outputs (two branches):**
  1. To **Add guarded test step** (fixed â€œheavy guardedâ€ test)
  2. To **Extract the agent checking sites** (per-URL detection site run)
- **Edge cases / failure modes:**
  - If downstream path errors, the loop can stop mid-run.
  - If loop-back connection is broken, it will only process the first batch.

---

### Block 3 â€” BrowserAct Runs (Guarded + Regular)
**Overview:** Uses BrowserAct to load pages and return raw diagnostic output (`$json.output.string`). One path always tests a heavy-guarded site; the other tests each URL from the list.

**Nodes involved:**
- Add guarded test step
- Check the site accessibility
- Extract the agent checking sites

#### Node: Add guarded test step
- **Type / role:** `Set` â€” injects a constant â€œheavy guardedâ€ target.
- **Configuration:**
  - Sets `Heavy_Guarded_Site` to `https://www.footlocker.co.uk/`
  - Note text is identical to the earlier URL list note (likely copied).
- **Inputs:** From **Loop Over URLs** (branch 1).
- **Outputs:** To **Check the site accessibility**.
- **Edge cases:** This value is not actually mapped into the BrowserAct call here; the subsequent BrowserAct node uses `{{ $json.urls }}`, not `Heavy_Guarded_Site` (see below). That means this â€œguarded stepâ€ may not do what the name implies unless BrowserAct uses defaults.

#### Node: Check the site accessibility
- **Type / role:** `BrowserAct` â€” runs a BrowserAct workflow to open the site and capture results.
- **Configuration (interpreted):**
  - Mode: `WORKFLOW`
  - BrowserAct workflowId: `76240546993093673`
  - Workflow config input mapping:
    - `Ip_Bot_check_Link` = `{{ $json.urls }}`
  - `open_incognito_mode: false`
- **Credentials:** BrowserAct API (â€œBrowserAct accountâ€).
- **Inputs:** From **Add guarded test step**.
- **Outputs:** To **Analyze the site results**.
- **Failure modes / edge cases:**
  - Wrong/disabled BrowserAct workflow ID â†’ execution failure.
  - If `urls` is undefined on this branch (likely), BrowserAct may:
    - use a template default (as hinted by the schema description), or
    - fail due to missing required input, depending on BrowserAct template configuration.
  - Site may block, present CAPTCHA, or return incomplete output; analysis must handle it.

#### Node: Extract the agent checking sites
- **Type / role:** `BrowserAct` â€” runs the same BrowserAct workflow per target URL.
- **Configuration (interpreted):**
  - Mode: `WORKFLOW`
  - workflowId: `76240546993093673`
  - `Ip_Bot_check_Link` = `{{ $json.urls }}` (here it exists: each loop item is a single URL from Split Out)
  - `open_incognito_mode: false`
- **Credentials:** BrowserAct API (â€œBrowserAct accountâ€).
- **Inputs:** From **Loop Over URLs** (branch 2).
- **Outputs:** To **Analyze the site results and generate a report**.
- **Failure modes / edge cases:**
  - Same as above (auth, workflowId, site blocks).
  - BrowserAct output schema changes (e.g., `output.string` missing) will break downstream LLM agent prompts.

**Sub-workflow reference:** Both BrowserAct nodes invoke BrowserAct workflow/template `76240546993093673` (external to n8n). It is expected to return something like:
- `output.string` (raw textual page/diagnostic content)

---

### Block 4 â€” AI Forensic Analysis (Per-site)
**Overview:** Two LLM â€œagentâ€ nodes analyze BrowserAct outputs and return strictly structured JSON: `{ "text": "..." }`. Each agent relies on an OpenRouter GPTâ€‘4o language model and a structured output parser.

**Nodes involved:**
- OpenRouter
- Structured Output Parser2
- Analyze the site results
- OpenRouter Chat Model
- Structured Output Parser
- Analyze the site results and generate a report

#### Node: OpenRouter
- **Type / role:** `LM Chat OpenRouter` â€” provides GPTâ€‘4o model for an agent.
- **Configuration:** Model `openai/gpt-4o`.
- **Credentials:** OpenRouter API (â€œOpenRouter accountâ€).
- **Connections:** Feeds the AI language model input of:
  - **Analyze the site results**
  - **Structured Output Parser2**
- **Failure modes:**
  - OpenRouter auth / quota / model availability issues.
  - Rate limiting when looping through many URLs.

#### Node: Structured Output Parser2
- **Type / role:** `Structured Output Parser` â€” enforces JSON schema and auto-fixes malformed LLM JSON.
- **Configuration:**
  - `autoFix: true`
  - Example schema: `{ "text": "ğŸ›¡ï¸ SECURITY DIAGNOSTIC REPORT ..."}`
- **Connections:** Provides `ai_outputParser` to **Analyze the site results**.
- **Failure modes:**
  - If LLM output is too malformed, autoFix may still fail.
  - If agent returns extra keys, parser may reject or attempt to coerce.

#### Node: Analyze the site results
- **Type / role:** `LangChain Agent` â€” validates whether the site actually loaded and checks for block/anti-bot indicators.
- **Key configuration:**
  - Prompt input: `Input : {{ $json.output.string }}`
  - System message: â€œSenior Scraping Integrity & Security Analystâ€ with step-by-step â€œload validation + forensic deep diveâ€
  - Output constraint: single JSON object with exactly one key `"text"` containing markdown string
  - `hasOutputParser: true` (uses Structured Output Parser2)
- **Inputs:** From **Check the site accessibility**.
- **Outputs:** To **Update Database1**.
- **Failure modes / edge cases:**
  - `$json.output.string` missing â†’ expression resolves to empty; LLM analysis becomes low-signal.
  - Very large text can hit token limits or cause truncation.
  - If block pages are images/scripts, raw text may be minimal â†’ false â€œsuccessâ€/â€œfailureâ€.

#### Node: OpenRouter Chat Model
- **Type / role:** `LM Chat OpenRouter` â€” GPTâ€‘4o model for the second agent.
- **Configuration:** Model `openai/gpt-4o`.
- **Connections:** Feeds the AI language model input of:
  - **Analyze the site results and generate a report**
  - **Structured Output Parser**
- **Failure modes:** Same as other OpenRouter node.

#### Node: Structured Output Parser
- **Type / role:** `Structured Output Parser` â€” enforces JSON `{ "text": "# ğŸ›¡ï¸ SECURITY DIAGNOSTIC REPORT ..." }`.
- **Configuration:**
  - `autoFix: true`
  - Example schema includes a markdown header and report body
- **Connections:** Provides `ai_outputParser` to **Analyze the site results and generate a report**.
- **Failure modes:** Same as other structured parser.

#### Node: Analyze the site results and generate a report
- **Type / role:** `LangChain Agent` â€” deeper forensic â€œruthless line-by-lineâ€ analysis and classification: Identified (Bot) / Suspicious / Clean (Human).
- **Key configuration:**
  - Prompt input: `Input : {{ $json.output.string }}`
  - System message emphasizes:
    - classify artifact (block page vs fingerprint leak vs success)
    - network forensics, UA/platform mismatch, automation leaks, CAPTCHA error codes
  - Output: strict JSON with only `"text"` markdown report
  - `hasOutputParser: true` (uses Structured Output Parser)
- **Inputs:** From **Extract the agent checking sites**.
- **Outputs:** To **Update Database** (append and continue loop).
- **Failure modes / edge cases:**
  - Same as above (missing output, oversized text).
  - Overconfident classification if site returns partial HTML.

---

### Block 5 â€” Storage in Google Sheets (Per-site) + Loop-back
**Overview:** Appends each AI-produced report into a single-column â€œResultâ€ field in Google Sheets. One append path loops back to continue processing URLs.

**Nodes involved:**
- Update Database
- Update Database1

#### Node: Update Database
- **Type / role:** `Google Sheets` â€” appends results for the detection-site analysis track.
- **Configuration:**
  - Operation: **Append**
  - Document: â€œIP, Fingerprint Integrity and Bot Detection Checkâ€
  - Sheet: â€œDataBaseâ€
  - Column mapping: `Result` = `{{ $json.output.text }}`
  - Mapping mode: â€œdefine belowâ€
- **Inputs:** From **Analyze the site results and generate a report**.
- **Outputs:** Back to **Loop Over URLs** (loop continuation).
- **Failure modes / edge cases:**
  - If the sheet doesnâ€™t have a `Result` header, append may create misaligned columns.
  - Large text may exceed Google Sheets cell limits (~50k chars) â†’ truncation/failure.
  - Auth / quota limits.

#### Node: Update Database1
- **Type / role:** `Google Sheets` â€” appends results for the â€œsite accessibilityâ€ guarded track.
- **Configuration:** Same as Update Database (append `Result` from `{{ $json.output.text }}`).
- **Inputs:** From **Analyze the site results**.
- **Outputs:** To **Fetch stored data** (this is important: it starts the aggregation path).
- **Failure modes:** Same as Update Database.

**Design note:** This introduces a timing risk: **Fetch stored data** can run before the URL loop finishes (because Update Database1 is not wired into the loop-back). Depending on execution timing, the final report may be generated with incomplete data.

---

### Block 6 â€” Fetch, Aggregate, Final AI Verdict, Slack
**Overview:** Reads all rows from the sheet, aggregates them into a single dataset, asks GPTâ€‘4o to produce a final GO/NOâ€‘GO summary, then posts to Slack.

**Nodes involved:**
- Fetch stored data
- Aggregate
- OpenRouter Chat Model1
- Structured Output Parser1
- Process final data
- Send Report

#### Node: Fetch stored data
- **Type / role:** `Google Sheets` â€” reads stored results from the sheet.
- **Configuration:** Operation not explicitly set in JSON (defaults to a â€œread/getâ€ operation in this node type/version). It targets:
  - Document: same spreadsheet
  - Sheet: â€œDataBaseâ€
- **Inputs:** From **Update Database1**.
- **Outputs:** To **Aggregate**.
- **Failure modes / edge cases:**
  - If the node defaults to â€œread all rowsâ€, large sheets can be slow/time out.
  - If it defaults to a different operation in your n8n version, results may be empty.

#### Node: Aggregate
- **Type / role:** `Aggregate` â€” combines multiple items into one structure for final analysis.
- **Configuration:** `aggregateAllItemData` (collect all item JSON into a combined object/array).
- **Inputs:** From **Fetch stored data**.
- **Outputs:** To **Process final data**.
- **Failure modes:** If incoming items are empty, final report will be based on empty set.

#### Node: OpenRouter Chat Model1
- **Type / role:** `LM Chat OpenRouter` â€” GPTâ€‘4o model for the final summarization agent.
- **Configuration:** Model `openai/gpt-4o`.
- **Connections:** Feeds AI language model input of:
  - **Process final data**
  - **Structured Output Parser1**
- **Failure modes:** Rate limits/quota.

#### Node: Structured Output Parser1
- **Type / role:** `Structured Output Parser` â€” enforces output JSON `{ "text": "..." }`.
- **Configuration:**
  - `autoFix: true`
  - Example schema is a long â€œSECURITY DIAGNOSTIC REPORTâ€¦â€
- **Connections:** Provides `ai_outputParser` to **Process final data**.

#### Node: Process final data
- **Type / role:** `LangChain Agent` â€” consolidates multiple site reports into final verdict.
- **Key configuration:**
  - Prompt input: `Input : {{ JSON.stringify($json.data, null, 2) }}`
  - System message: â€œLead Automation Security Auditorâ€
  - Required sections in `text`:
    1) FINAL MISSION VERDICT (GO/NOâ€‘GO)  
    2) SCORECARD  
    3) CRITICAL FAILURES  
    4) CONSISTENCY CHECK  
    5) RECOMMENDATION
  - Constraint: â€œDo not output markdown code blocks.â€
  - `hasOutputParser: true`
- **Inputs:** From **Aggregate**.
- **Outputs:** To **Send Report**.
- **Failure modes / edge cases:**
  - If Aggregate outputs a different field than `data`, the stringify expression will be wrong.
  - Very large aggregated data can exceed model context.
  - Inconsistent per-row formatting (freeform markdown) may reduce summarization quality.

#### Node: Send Report
- **Type / role:** `Slack` â€” posts final summary to a Slack channel.
- **Configuration:**
  - Operation: send message (by providing `text`)
  - Channel: `all-browseract-workflow-test` (ID `C09KLV9DJSX`)
  - Text: `{{ $json.output.text }}`
- **Credentials:** Slack API (â€œSlack account 2â€).
- **Failure modes / edge cases:**
  - Slack token scopes missing (`chat:write`) or channel access issues.
  - Message length limits; very long text may be truncated or rejected.

---

### Block 7 â€” Documentation / Notes (Sticky Notes)
**Overview:** Provides embedded operational guidance and links.

**Nodes involved:**
- Documentation (sticky note)
- Step 1 Explanation (sticky note)
- Step 2 Explanation (sticky note)
- Step 3 Explanation (sticky note)
- Sticky Note (YouTube embed)

No runtime impact, but contents are referenced in the Summary Table.

---

## 3. Summary Table

| Node Name | Node Type | Functional Role | Input Node(s) | Output Node(s) | Sticky Note |
|---|---|---|---|---|---|
| Execute manually | n8n-nodes-base.manualTrigger | Manual entry point | â€” | Clear Database | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a list of target URLsâ€¦ |
| Clear Database | n8n-nodes-base.googleSheets | Clear storage sheet (keep headers) | Execute manually | Define Target URLs | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a list of target URLsâ€¦ |
| Define Target URLs | n8n-nodes-base.set | Define array of detection URLs | Clear Database | Split Out | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a list of target URLsâ€¦ |
| Split Out | n8n-nodes-base.splitOut | Turn URL array into items | Define Target URLs | Loop Over URLs | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a list of target URLsâ€¦ |
| Loop Over URLs | n8n-nodes-base.splitInBatches | Batch loop controller | Split Out; Update Database | Add guarded test step; Extract the agent checking sites | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a list of target URLsâ€¦ |
| Add guarded test step | n8n-nodes-base.set | Define heavy-guarded site URL | Loop Over URLs | Check the site accessibility | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a list of target URLsâ€¦ |
| Check the site accessibility | n8n-nodes-browseract.browserAct | BrowserAct run (accessibility / guarded) | Add guarded test step | Analyze the site results | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a list of target URLsâ€¦ |
| OpenRouter | @n8n/n8n-nodes-langchain.lmChatOpenRouter | LLM provider (GPTâ€‘4o) for â€œAnalyze the site resultsâ€ | â€” (AI connection) | Analyze the site results; Structured Output Parser2 (AI) | ### ğŸ›¡ï¸ Step 2: Forensic Analysis â€” For each site visited, an AI â€œSecurity Analystâ€ parses the raw textâ€¦ |
| Structured Output Parser2 | @n8n/n8n-nodes-langchain.outputParserStructured | Enforce JSON `{text}` for guarded analysis | â€” (AI connection) | Analyze the site results (AI parser) | ### ğŸ›¡ï¸ Step 2: Forensic Analysis â€” For each site visited, an AI â€œSecurity Analystâ€ parses the raw textâ€¦ |
| Analyze the site results | @n8n/n8n-nodes-langchain.agent | AI validates load + detects blocks | Check the site accessibility | Update Database1 | ### ğŸ›¡ï¸ Step 2: Forensic Analysis â€” For each site visited, an AI â€œSecurity Analystâ€ parses the raw textâ€¦ |
| Update Database1 | n8n-nodes-base.googleSheets | Append guarded analysis to sheet | Analyze the site results | Fetch stored data | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reports are storedâ€¦ final AI agent reviewsâ€¦ |
| Fetch stored data | n8n-nodes-base.googleSheets | Read sheet rows for aggregation | Update Database1 | Aggregate | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reports are storedâ€¦ final AI agent reviewsâ€¦ |
| Aggregate | n8n-nodes-base.aggregate | Combine rows into a single dataset | Fetch stored data | Process final data | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reports are storedâ€¦ final AI agent reviewsâ€¦ |
| OpenRouter Chat Model1 | @n8n/n8n-nodes-langchain.lmChatOpenRouter | LLM provider (GPTâ€‘4o) for final summary | â€” (AI connection) | Process final data; Structured Output Parser1 (AI) | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reports are storedâ€¦ final AI agent reviewsâ€¦ |
| Structured Output Parser1 | @n8n/n8n-nodes-langchain.outputParserStructured | Enforce JSON `{text}` for final summary | â€” (AI connection) | Process final data (AI parser) | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reports are storedâ€¦ final AI agent reviewsâ€¦ |
| Process final data | @n8n/n8n-nodes-langchain.agent | Final GO/NOâ€‘GO consolidation | Aggregate | Send Report | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reports are storedâ€¦ final AI agent reviewsâ€¦ |
| Send Report | n8n-nodes-base.slack | Post final report to Slack | Process final data | â€” | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reports are storedâ€¦ final AI agent reviewsâ€¦ |
| Extract the agent checking sites | n8n-nodes-browseract.browserAct | BrowserAct run per detection URL | Loop Over URLs | Analyze the site results and generate a report | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a list of target URLsâ€¦ |
| OpenRouter Chat Model | @n8n/n8n-nodes-langchain.lmChatOpenRouter | LLM provider (GPTâ€‘4o) for per-site forensic report | â€” (AI connection) | Analyze the site results and generate a report; Structured Output Parser (AI) | ### ğŸ›¡ï¸ Step 2: Forensic Analysis â€” For each site visited, an AI â€œSecurity Analystâ€ parses the raw textâ€¦ |
| Structured Output Parser | @n8n/n8n-nodes-langchain.outputParserStructured | Enforce JSON `{text}` for per-site forensic report | â€” (AI connection) | Analyze the site results and generate a report (AI parser) | ### ğŸ›¡ï¸ Step 2: Forensic Analysis â€” For each site visited, an AI â€œSecurity Analystâ€ parses the raw textâ€¦ |
| Analyze the site results and generate a report | @n8n/n8n-nodes-langchain.agent | AI forensic report per detection site | Extract the agent checking sites | Update Database | ### ğŸ›¡ï¸ Step 2: Forensic Analysis â€” For each site visited, an AI â€œSecurity Analystâ€ parses the raw textâ€¦ |
| Update Database | n8n-nodes-base.googleSheets | Append per-site report; loop-back continuation | Analyze the site results and generate a report | Loop Over URLs | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reports are storedâ€¦ final AI agent reviewsâ€¦ |
| OpenRouter Chat Model (unused) | @n8n/n8n-nodes-langchain.lmChatOpenRouter | LLM provider node present but not connected | â€” | â€” |  |
| Structured Output Parser (unused) | @n8n/n8n-nodes-langchain.outputParserStructured | Parser node present but not connected | â€” | â€” |  |
| Documentation | n8n-nodes-base.stickyNote | Embedded setup notes & links | â€” | â€” | ## âš¡ Workflow Overview & Setup â€” Summary/Requirements/Links (https://docs.browseract.com) |
| Step 1 Explanation | n8n-nodes-base.stickyNote | Embedded explanation of step 1 | â€” | â€” | ### ğŸ•µï¸ Step 1: Multi-Site Testing â€” The workflow iterates through a listâ€¦ |
| Step 2 Explanation | n8n-nodes-base.stickyNote | Embedded explanation of step 2 | â€” | â€” | ### ğŸ›¡ï¸ Step 2: Forensic Analysis â€” For each site visited, an AIâ€¦ |
| Step 3 Explanation | n8n-nodes-base.stickyNote | Embedded explanation of step 3 | â€” | â€” | ### ğŸ“Š Step 3: Aggregation & Reporting â€” All individual site reportsâ€¦ |
| Sticky Note | n8n-nodes-base.stickyNote | Embedded video link | â€” | â€” | @[youtube](64cKXeY52NQ) |

**Note on â€œunusedâ€ rows:** The workflow JSON includes **OpenRouter Chat Model** and **Structured Output Parser** nodes that are connected, and also separate nodes named **OpenRouter** / **Structured Output Parser2**, plus a pair **OpenRouter Chat Model1** / **Structured Output Parser1**. There is no extra disconnected pair beyond these; however, the naming is confusing. If in your n8n canvas you see duplicates, verify which ones are actually wired into the agents via AI connections.

---

## 4. Reproducing the Workflow from Scratch

1) **Create a new workflow**
- Name it: â€œAudit browser fingerprint and IP integrity to Slack reportsâ€ (or your preferred name).
- Ensure **Settings â†’ Execution Order** is `v1` (as in the JSON).

2) **Add Trigger**
- Add node: **Manual Trigger**  
  - Name: â€œExecute manuallyâ€

3) **Add Google Sheets: Clear**
- Add node: **Google Sheets**
  - Name: â€œClear Databaseâ€
  - Credentials: connect a **Google Sheets OAuth2** credential with access to the spreadsheet
  - Operation: **Clear**
  - Document: select your spreadsheet (create one if needed)
  - Sheet: select tab â€œDataBaseâ€
  - Enable: **Keep First Row** = true
- Connect: **Execute manually â†’ Clear Database**

4) **Add Set: URL list**
- Add node: **Set**
  - Name: â€œDefine Target URLsâ€
  - Add field `urls` (Type: Array) with value like:
    - `["https://www.browserscan.net/bot-detection", "https://www.ipqualityscore.com/free-ip-lookup-proxy-vpn-test", "https://www.ip-score.com/"]`
- Connect: **Clear Database â†’ Define Target URLs**

5) **Split URL array into items**
- Add node: **Split Out**
  - Name: â€œSplit Outâ€
  - Field to split out: `urls`
- Connect: **Define Target URLs â†’ Split Out**

6) **Add batching loop**
- Add node: **Split In Batches**
  - Name: â€œLoop Over URLsâ€
  - Configure batch size as desired (default is fine for small lists)
  - Options: `Reset` = false
- Connect: **Split Out â†’ Loop Over URLs**

7) **BrowserAct credentials & external workflow**
- In n8n, create a **BrowserAct API** credential.
- In BrowserAct, ensure you have a BrowserAct workflow/template available (the JSON expects):
  - Template/workflow name: â€œIP, Fingerprint Integrity and Bot Detection Checkâ€
  - BrowserAct workflowId: `76240546993093673` (replace with yours)
  - It should accept an input variable like `Ip_Bot_check_Link` and return an output containing raw results (commonly `output.string`).

8) **Branch A (regular per-URL testing): BrowserAct**
- Add node: **BrowserAct**
  - Name: â€œExtract the agent checking sitesâ€
  - Type: WORKFLOW
  - workflowId: your BrowserAct workflow id
  - Map input: `Ip_Bot_check_Link` = `{{ $json.urls }}`
  - Incognito: false (optional)
- Connect: **Loop Over URLs (output 2) â†’ Extract the agent checking sites**

9) **Branch A: LLM model + structured parser + agent**
- Add node: **OpenRouter Chat Model**
  - Name: â€œOpenRouter Chat Modelâ€
  - Credentials: OpenRouter API key
  - Model: `openai/gpt-4o`
- Add node: **Structured Output Parser**
  - Name: â€œStructured Output Parserâ€
  - Auto-fix: true
  - Schema example: `{ "text": "# ğŸ›¡ï¸ SECURITY DIAGNOSTIC REPORT\n\n..." }`
- Add node: **AI Agent (LangChain Agent)**
  - Name: â€œAnalyze the site results and generate a reportâ€
  - Prompt/input text: `Input : {{ $json.output.string }}`
  - System message: use the â€œElite Security & Bot Detection Analystâ€ system message from the workflow (ensure it demands a single JSON with only `text`)
  - Enable: â€œHas Output Parserâ€
- Wire AI connections:
  - **OpenRouter Chat Model â†’ (AI Language Model) â†’ Agent**
  - **Structured Output Parser â†’ (AI Output Parser) â†’ Agent**
- Connect main flow:
  - **Extract the agent checking sites â†’ Agent**

10) **Branch A: Append to Google Sheets + loop-back**
- Add node: **Google Sheets**
  - Name: â€œUpdate Databaseâ€
  - Operation: **Append**
  - Document: same spreadsheet
  - Sheet: â€œDataBaseâ€
  - Map column: `Result` = `{{ $json.output.text }}`
  - Ensure the sheet has a header column named `Result`
- Connect: **Agent â†’ Update Database**
- Connect loop-back: **Update Database â†’ Loop Over URLs** (so the next URL is processed)

11) **Branch B (guarded accessibility check): Set + BrowserAct**
- Add node: **Set**
  - Name: â€œAdd guarded test stepâ€
  - Field `Heavy_Guarded_Site` = `https://www.footlocker.co.uk/`
- Add node: **BrowserAct**
  - Name: â€œCheck the site accessibilityâ€
  - Type: WORKFLOW
  - workflowId: same BrowserAct workflow id
  - Important: decide what input to pass:
    - If you want the heavy site, map `Ip_Bot_check_Link` = `{{ $json.Heavy_Guarded_Site }}`
    - (The provided JSON maps `{{ $json.urls }}` which likely wonâ€™t exist on this branch.)
- Connect: **Loop Over URLs (output 1) â†’ Add guarded test step â†’ Check the site accessibility**

12) **Branch B: LLM model + structured parser + agent**
- Add node: **OpenRouter Chat Model**
  - Name: â€œOpenRouterâ€
  - Model: `openai/gpt-4o`
- Add node: **Structured Output Parser**
  - Name: â€œStructured Output Parser2â€
  - Auto-fix: true
  - Schema example: `{ "text": "..." }`
- Add node: **AI Agent**
  - Name: â€œAnalyze the site resultsâ€
  - Prompt: `Input : {{ $json.output.string }}`
  - System message: â€œSenior Scraping Integrity & Security Analystâ€¦â€
  - Has Output Parser: enabled
- Wire AI connections:
  - **OpenRouter â†’ (AI Language Model) â†’ Analyze the site results**
  - **Structured Output Parser2 â†’ (AI Output Parser) â†’ Analyze the site results**
- Connect main flow:
  - **Check the site accessibility â†’ Analyze the site results**

13) **Branch B: Append to Google Sheets**
- Add node: **Google Sheets**
  - Name: â€œUpdate Database1â€
  - Operation: Append
  - Map: `Result` = `{{ $json.output.text }}`
- Connect: **Analyze the site results â†’ Update Database1**

14) **Fetch all stored results**
- Add node: **Google Sheets**
  - Name: â€œFetch stored dataâ€
  - Operation: â€œRead/Get Allâ€ (depending on node UI; configure to read all rows from â€œDataBaseâ€)
- Connect: **Update Database1 â†’ Fetch stored data**

15) **Aggregate items**
- Add node: **Aggregate**
  - Name: â€œAggregateâ€
  - Mode: **Aggregate All Item Data** (so you get one combined object)
- Connect: **Fetch stored data â†’ Aggregate**

16) **Final AI consolidation**
- Add node: **OpenRouter Chat Model**
  - Name: â€œOpenRouter Chat Model1â€
  - Model: `openai/gpt-4o`
- Add node: **Structured Output Parser**
  - Name: â€œStructured Output Parser1â€
  - Auto-fix: true
  - Schema example: `{ "text": "..." }`
- Add node: **AI Agent**
  - Name: â€œProcess final dataâ€
  - Text: `Input : {{ JSON.stringify($json.data, null, 2) }}`
  - System message: â€œLead Automation Security Auditorâ€¦â€ (requires GO/NOâ€‘GO sections; no markdown code blocks)
  - Has Output Parser: enabled
- Wire AI connections:
  - **OpenRouter Chat Model1 â†’ (AI Language Model) â†’ Process final data**
  - **Structured Output Parser1 â†’ (AI Output Parser) â†’ Process final data**
- Connect main flow:
  - **Aggregate â†’ Process final data**

17) **Slack posting**
- Add node: **Slack**
  - Name: â€œSend Reportâ€
  - Credentials: Slack OAuth/token with `chat:write`
  - Channel: choose your channel (e.g., `all-browseract-workflow-test`)
  - Message text: `{{ $json.output.text }}`
- Connect: **Process final data â†’ Send Report**

18) **(Optional but recommended) Fix the run-completion logic**
- As built in the provided JSON, the â€œFetch stored dataâ€ path may start before the per-URL loop finishes.
- To make the final Slack report reliable, add a â€œWhen loop doneâ€ mechanism (e.g., use Split in Batches completion branch, or collect items then fetch once after loop completes).

---

## 5. General Notes & Resources

| Note Content | Context or Link |
|---|---|
| â€œThis automation continuously monitors the integrity of your IP address and browser fingerprintâ€¦ Requirements: BrowserAct, OpenRouter, Google Sheets, Slack. Mandatory: BrowserAct API (Template: IP, Fingerprint Integrity and Bot Detection Check)â€ | Sticky note: â€œDocumentationâ€ |
| How to Find Your BrowserAct API Key & Workflow ID | https://docs.browseract.com |
| How to Connect n8n to BrowserAct | https://docs.browseract.com |
| How to Use & Customize BrowserAct Templates | https://docs.browseract.com |
| Video reference | @[youtube](64cKXeY52NQ) |

Disclaimer (provided by user): Le texte fourni provient exclusivement dâ€™un workflow automatisÃ© rÃ©alisÃ© avec n8n, un outil dâ€™intÃ©gration et dâ€™automatisation. Ce traitement respecte strictement les politiques de contenu en vigueur et ne contient aucun Ã©lÃ©ment illÃ©gal, offensant ou protÃ©gÃ©. Toutes les donnÃ©es manipulÃ©es sont lÃ©gales et publiques.