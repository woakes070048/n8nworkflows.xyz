{"id":"KXXAFjp2GaYwDN3BDjjML","meta":{"instanceId":"f5dbadefe65ad5d7929fc1f26badb9a1c520f5feeae2557ecb763b3426f291b2","templateCredsSetupCompleted":true},"name":"Self hosted RAG using Ollama and Qdrant","tags":[],"nodes":[{"id":"80b20667-49e6-4d2a-9e0a-aa159ff701da","name":"Default Data Loader","type":"@n8n/n8n-nodes-langchain.documentDefaultDataLoader","position":[112,96],"parameters":{"options":{"splitPages":true},"dataType":"binary"},"typeVersion":1.1},{"id":"02ffa064-6225-41ab-8952-6e2ca52f3a0f","name":"Embeddings Ollama","type":"@n8n/n8n-nodes-langchain.embeddingsOllama","position":[352,560],"parameters":{"model":"nomic-embed-text:latest"},"credentials":{"ollamaApi":{"id":"boTZGVz1obqXBiZ5","name":"Ollama account"}},"typeVersion":1},{"id":"c45b9793-b55c-43e1-8b48-539a9e7e3bd2","name":"Sticky Note","type":"n8n-nodes-base.stickyNote","position":[-1008,-176],"parameters":{"width":528,"height":1200,"content":"\n## Try It\n### This n8n template provides a self hosted RAG implementation.\n\n### How it works\n* Provides one workflow to maintain the knowledge base and another one to query the knowledge base.\n* Uploaded documents are saved into the Qdrant vector store.\n* When a query is made, the most relevant documents are retrieved from the vector store and sent to the LLM as context for generating a response.\n\n\n### How to use\n* Start the workflow by clicking **Execute workflow**\n* Use the file upload form to upload a document into the knowledge base (Qdrant db).\n* Click **Open chat** to start asking questions related to the uploaded documents.\n\n### Setup steps\nBelow steps show how to setup on Amazon Linux. Consult your OS for respective steps\n\n* Install Ollama on prem\n```\nmkdir ollama\ncd ollama\ncurl -fsSL https://ollama.com/install.sh | sh\nollama --version\n```\n* Install required models ( in Amazon Linux)\n\n```\n ollama pull llama3:8b\n ollama pull mistral:7b\n ollama pull nomic-embed-text:latest\n```\n* Access ollama via http://localhost:11434\n* Fire up Qdrant  (e.g.  via docker)\n`docker run -p 6333:6333 qdrant/qdrant`. \n* Access Qdrant via `http://localhost:6333/dashboard` \n* Create a Qdrant collection named `knowledge-base` configured with vector length of 768.\n* NB: Do not forget a persistent docker volume for Qdrant if you want to keep the data when using docker.\n* Point the nodes to the respective on premise Qdrant and Ollama runtimes.\n\n\n### Need Help?\nJoin the [Discord](https://discord.com/invite/XPKeKXeB7d) or ask in the [Forum](https://community.n8n.io/)!\n\nHappy RAGing!"},"typeVersion":1},{"id":"4e3202d4-7b64-49a1-8f7f-63f2cd02e815","name":"Sticky Note1","type":"n8n-nodes-base.stickyNote","position":[-384,-160],"parameters":{"color":7,"width":704,"height":496,"content":"## 1. Update Knowledge base\n"},"typeVersion":1},{"id":"3306b8ee-e953-4218-9f7e-60a10cc26c66","name":"When chat message received","type":"@n8n/n8n-nodes-langchain.chatTrigger","position":[608,-80],"webhookId":"04711830-0176-44d1-87b7-fd7b403f46d0","parameters":{"public":true,"options":{"responseMode":"lastNode"},"initialMessages":"Kwema ? ðŸ‘‹\nMy name is KB. How can I assist you today?"},"typeVersion":1.4},{"id":"4aaafa6c-286b-495e-a87b-87e76b789862","name":"AI Agent","type":"@n8n/n8n-nodes-langchain.agent","position":[832,-80],"parameters":{"options":{"systemMessage":"FORCE TOOL USAGE. DO NOT guess. \nALWAYS use the Vector Store tool before answering.\nFetch relevant info from the Qdrant vector store. \nUse the retrieved results to answer the user query.\n\n"}},"typeVersion":3.1},{"id":"1cf662db-7d82-4b09-9f6b-1025d694615a","name":"Ollama Chat Model","type":"@n8n/n8n-nodes-langchain.lmChatOllama","position":[640,128],"parameters":{"model":"mistral:7b","options":{"topK":-1}},"credentials":{"ollamaApi":{"id":"boTZGVz1obqXBiZ5","name":"Ollama account"}},"typeVersion":1},{"id":"068c18a2-bc98-4975-851e-c6fe462d6753","name":"Sticky Note2","type":"n8n-nodes-base.stickyNote","position":[480,-160],"parameters":{"color":7,"width":816,"height":496,"content":"## 2. Query Knowledge base"},"typeVersion":1},{"id":"b9f2ba62-e432-43e3-952e-261b83420229","name":"Simple Memory","type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","position":[848,128],"parameters":{},"typeVersion":1.3},{"id":"4072d63b-b349-4089-909b-839e5fb33567","name":"Add to Qdrant Vector Store","type":"@n8n/n8n-nodes-langchain.vectorStoreQdrant","position":[-80,-64],"parameters":{"mode":"insert","options":{},"qdrantCollection":{"__rl":true,"mode":"list","value":"knowledge-base","cachedResultName":"knowledge-base"}},"credentials":{"qdrantApi":{"id":"xwO4I0eULS9blwwa","name":"QdrantApi account"}},"typeVersion":1.3},{"id":"019770da-2265-46d4-848f-a3e9305f401d","name":"Read from Qdrant Vector Store","type":"@n8n/n8n-nodes-langchain.vectorStoreQdrant","position":[992,128],"parameters":{"mode":"retrieve-as-tool","topK":3,"options":{},"toolDescription":"ALWAYS Use this knowledge base to answer questions from the user","qdrantCollection":{"__rl":true,"mode":"list","value":"knowledge-base","cachedResultName":"knowledge-base"},"includeDocumentMetadata":false},"credentials":{"qdrantApi":{"id":"xwO4I0eULS9blwwa","name":"QdrantApi account"}},"typeVersion":1.3},{"id":"5a942bd4-8794-442d-a751-f50eb9c62b88","name":"Upload document","type":"n8n-nodes-base.formTrigger","position":[-288,-64],"webhookId":"bcfe7867-604e-4dd5-a7a0-74fa32955b25","parameters":{"options":{},"formTitle":"Upload","formFields":{"values":[{"fieldLabel":"Doc Name"},{"fieldType":"file","fieldLabel":"File"}]},"formDescription":"Poor mans Knowledge base"},"typeVersion":2.5}],"active":true,"pinData":{},"settings":{"binaryMode":"separate","availableInMCP":false,"executionOrder":"v1"},"versionId":"b286da3a-10bc-42d3-9808-97fe23e4f691","connections":{"Simple Memory":{"ai_memory":[[{"node":"AI Agent","type":"ai_memory","index":0}]]},"Upload document":{"main":[[{"node":"Add to Qdrant Vector Store","type":"main","index":0}]]},"Embeddings Ollama":{"ai_embedding":[[{"node":"Add to Qdrant Vector Store","type":"ai_embedding","index":0},{"node":"Read from Qdrant Vector Store","type":"ai_embedding","index":0}]]},"Ollama Chat Model":{"ai_languageModel":[[{"node":"AI Agent","type":"ai_languageModel","index":0}]]},"Default Data Loader":{"ai_document":[[{"node":"Add to Qdrant Vector Store","type":"ai_document","index":0}]]},"When chat message received":{"main":[[{"node":"AI Agent","type":"main","index":0}]]},"Read from Qdrant Vector Store":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]}}}