Create AI screencast videos with Claude, VEED, OpenAI and automated slides

https://n8nworkflows.xyz/workflows/create-ai-screencast-videos-with-claude--veed--openai-and-automated-slides-12728


# Create AI screencast videos with Claude, VEED, OpenAI and automated slides

## 1. Workflow Overview

**Workflow name:** Create AI screencast videos with VEED and automated slides  
**Purpose:** Automatically generate a â€œscreencast-styleâ€ video combining:
- A **talking-head avatar** (image + voiceover â†’ lip-synced video via VEED)
- A set of **AI-generated presentation slides** (images generated from Claude-authored prompts via FAL)
- A final **composited landscape video** (slides as main area + avatar as picture-in-picture) rendered by **Creatomate**, then uploaded to **Google Drive** and logged to **Google Sheets**.

**Typical use cases**
- Short thought-leadership or product explainers (25â€“40 seconds)
- Social content with consistent slide aesthetics and a presenter overlay
- Rapid generation of branded content variants (topic, intention, audience, style)

### 1.1 Input & Configuration
Manual start â†’ central configuration for topic, branding, timing, style, and API keys.

### 1.2 AI Planning (Claude)
Build a structured prompt â†’ call Anthropic â†’ parse JSON response into:
- voiceover script (or use custom script)
- slide prompts (16:9)
- optional avatar prompt (unless custom avatar URL provided)
- caption + hashtags
Also calculates slide count/duration estimates and picks voice ID.

### 1.3 Parallel Production
Splits into two flows:
- **Avatar flow:** avatar image (OpenAI or custom URL) â†’ ElevenLabs TTS â†’ VEED talking head video
- **Slides flow:** expand slides â†’ generate slide images via FAL Flux Pro â†’ aggregate/sort into ordered list

### 1.4 Composition & Render (Creatomate)
Merge avatar + slides â†’ build Creatomate element tree (optionally with background) â†’ start render â†’ poll until succeeded.

### 1.5 Output
Download final MP4 â†’ upload to Google Drive â†’ log metadata to Google Sheets â†’ return final summary object.

---

## 2. Block-by-Block Analysis

### Block 1 â€” Input & Workflow Configuration
**Overview:** Entry point and a single â€œconfiguration objectâ€ that drives all downstream behavior (topic, style, timing, API keys, voice/avatar/script overrides).  
**Nodes involved:**  
- When clicking 'Execute workflow'
- âš™ï¸ Workflow Configuration

#### Node: When clicking 'Execute workflow'
- **Type / role:** Manual Trigger (`n8n-nodes-base.manualTrigger`) â€“ starts execution manually.
- **Configuration choices:** No parameters.
- **Outputs:** One empty item to the next node.
- **Failure modes:** None (except workflow not executed).

#### Node: âš™ï¸ Workflow Configuration
- **Type / role:** Code node â€“ returns one item containing all runtime settings.
- **Key settings produced:**
  - Content: `topic`, `intention`, `brand_name`, `target_audience`, `trending_hashtags`
  - Slide style: `slide_style` (predefined styles)
  - Timing: `seconds_per_slide` (used later to estimate slide count)
  - Optional background: `background` (empty / gradient array / image URL)
  - API keys: `anthropic_api_key`, `openai_api_key`, `elevenlabs_api_key`, `creatomate_api_key`, `fal_api_key`
  - Voice: `voice_selection`
  - Avatar overrides: `custom_avatar_description`, `custom_avatar_image_url`
  - Script override: `custom_script`
- **Input/Output:** Trigger â†’ Build Claude Prompt.
- **Edge cases / failures:**
  - Missing/invalid API keys will later surface as 401/403 errors in HTTP nodes.
  - `background` type must match expected patterns:
    - `""` for none
    - URL string for image background
    - array of hex colors for gradient background
- **Version requirements:** Code node v2.

---

### Block 2 â€” AI Planning with Claude (prompt â†’ content â†’ parsed plan)
**Overview:** Generates a detailed Claude prompt based on config, requests JSON-only output from Anthropic, then parses and normalizes it into a consistent internal structure (including voice ID selection and duration calculations).  
**Nodes involved:**  
- ğŸ§  Build Claude Prompt  
- ğŸ¤– Claude: Generate Content  
- ğŸ“‹ Parse Claude Response

#### Node: ğŸ§  Build Claude Prompt
- **Type / role:** Code node â€“ constructs an instruction prompt for Claude, including a strict JSON schema response format.
- **Configuration choices (interpreted):**
  - Selects one of 5 slide design systems (`slideStyles`) using `config.slide_style`.
  - If a **custom script** is provided, estimates slide count from word count and `seconds_per_slide`, constrained 3â€“8.
  - If **custom avatar URL** is provided, skips avatar prompt generation requirements.
  - Builds a JSON â€œresponse formatâ€ template; instructs Claude to output **only valid JSON**.
- **Key variables added to output:**
  - `claude_prompt`, `slide_style_config`, `estimated_slides`
  - flags: `has_custom_avatar`, `has_custom_avatar_url`, `has_custom_script`
- **Input/Output:** Configuration â†’ Claude HTTP request.
- **Failure modes:** Expression/JS errors if config fields are missing or non-strings (rare, since config node controls shape).

#### Node: ğŸ¤– Claude: Generate Content
- **Type / role:** HTTP Request â€“ calls Anthropic Messages API.
- **Configuration choices:**
  - POST `https://api.anthropic.com/v1/messages`
  - Model: `claude-sonnet-4-20250514`
  - `max_tokens: 3000`
  - Sends one user message whose `content` is the serialized prompt text.
  - Headers:
    - `x-api-key: {{$json.anthropic_api_key}}`
    - `anthropic-version: 2023-06-01`
    - `Content-Type: application/json`
- **Input/Output:** Build Claude Prompt â†’ Parse Claude Response.
- **Failure modes:**
  - 401/403 if key invalid
  - 429 rate limits
  - 400 if payload malformed (less likely)
  - Timeout/network issues

#### Node: ğŸ“‹ Parse Claude Response
- **Type / role:** Code node â€“ extracts Claudeâ€™s text, strips possible code fences, JSON-parses, and applies robust fallbacks.
- **Normalization performed:**
  - If JSON parse fails, creates fallback:
    - default `audio_script`
    - default 5 slides with safe prompts
    - default `avatar_prompt`, caption, theme, language
  - Determines ElevenLabs `voice_id` from `voice_selection` map:
    - cristina, enrique, susie, jeff, custom
  - Forces `language` to `es` if Spanish voice chosen.
  - Chooses avatar strategy:
    - If `has_custom_avatar_url` â†’ no avatar prompt needed downstream
    - Else if `has_custom_avatar` â†’ builds a portrait prompt from `custom_avatar_description`
    - Else uses Claude `avatar_prompt` or fallback prompt
  - Determines final script:
    - `custom_script` wins; else Claude `audio_script`; else fallback
  - Calculates:
    - `script_word_count`
    - `estimated_duration` â‰ˆ ceil(words/2.5) + 2 seconds buffer
    - `num_slides` from Claude slides length (or generated defaults)
    - `duration_per_slide = estimated_duration / num_slides`
  - Determines `background_type`:
    - `"none"` / `"url"` / `"gradient"` and sets `background_value`
- **Outputs:** A single normalized item containing:
  - `script_audio`, `slides[]`, `avatar_prompt`, `voice_id`, timing, keys, etc.
- **Failure modes:**
  - If Claude returns unexpected structure, JSON parse fallback is used.
  - If `slides` empty and duration calc yields edge values, default slides are generated.
- **Note:** This node references data from `ğŸ§  Build Claude Prompt` by name using `$('ğŸ§  Build Claude Prompt').item.json`.

---

### Block 3 â€” Parallelization Router
**Overview:** Duplicates the normalized data into two items and routes each into either the avatar pipeline or the slides pipeline.  
**Nodes involved:**  
- ğŸ”€ Split into Flows  
- ğŸ”€ Avatar Flow?  
- ğŸ”€ Slides Flow?

#### Node: ğŸ”€ Split into Flows
- **Type / role:** Code node â€“ emits two items:
  - same JSON + `flow: "avatar"`
  - same JSON + `flow: "slides"`
- **Input/Output:** Parse Claude Response â†’ both IF routers.
- **Failure modes:** None typical.

#### Node: ğŸ”€ Avatar Flow?
- **Type / role:** IF node â€“ checks `{{$json.flow}} == "avatar"`.
- **True output:** goes to â€œHas Custom Avatar URL?â€
- **False output:** unused (implicit discard).

#### Node: ğŸ”€ Slides Flow?
- **Type / role:** IF node â€“ checks `{{$json.flow}} == "slides"`.
- **True output:** goes to â€œExpand Slidesâ€
- **False output:** unused.

---

### Block 4A â€” Avatar + Audio + Talking Head (VEED)
**Overview:** Produces the presenter video: choose avatar source (custom URL or OpenAI image), generate voiceover with ElevenLabs, upload assets to temporary hosting, then create a lip-synced video via VEED.  
**Nodes involved:**  
- ğŸ–¼ï¸ Has Custom Avatar URL?  
- ğŸ“¸ Use Custom Avatar URL  
- ğŸ¨ Generate Avatar (OpenAI)  
- ğŸ“¸ Extract Avatar Image  
- â˜ï¸ Upload Avatar Image  
- ğŸ’¾ Store Avatar URL  
- ğŸ”Š Generate Audio (ElevenLabs)  
- ğŸµ Convert Audio  
- â˜ï¸ Upload Audio  
- ğŸ’¾ Store Audio URL  
- ğŸ¬ Generate Talking Head (VEED)  
- ğŸ“¹ Extract VEED Video URL

#### Node: ğŸ–¼ï¸ Has Custom Avatar URL?
- **Type / role:** IF â€“ checks boolean `has_custom_avatar_url == true`.
- **True path:** Use Custom Avatar URL (skip generation/upload)
- **False path:** Generate Avatar (OpenAI)

#### Node: ğŸ“¸ Use Custom Avatar URL
- **Type / role:** Code â€“ sets `avatar_image_url = custom_avatar_image_url`.
- **Used when:** config provided a direct public URL.
- **Failure modes:** If URL is not publicly accessible, VEED may fail later.

#### Node: ğŸ¨ Generate Avatar (OpenAI)
- **Type / role:** HTTP Request â€“ OpenAI Images generation.
- **Request:**
  - POST `https://api.openai.com/v1/images/generations`
  - model `gpt-image-1`
  - `prompt = $json.avatar_prompt`
  - `size: 1024x1536`, `quality: high`
  - Authorization header: `Bearer {{$json.openai_api_key}}`
- **Output:** base64 image in `data[0].b64_json` (expected).
- **Failure modes:** 401/429, safety refusals, schema changes, no `b64_json` returned.

#### Node: ğŸ“¸ Extract Avatar Image
- **Type / role:** Code â€“ converts OpenAI base64 result to **binary** field `avatar_image` (PNG).
- **Important detail:** Throws hard error if no base64 data found.
- **Output:** JSON (previous data) + binary `{ avatar_image: ... }`
- **Failure modes:** missing `b64_json` â†’ workflow stops unless error handling added.

#### Node: â˜ï¸ Upload Avatar Image
- **Type / role:** HTTP Request â€“ uploads binary file to `tmpfiles.org`.
- **Request:** multipart/form-data with `file` = `avatar_image`.
- **Output:** JSON containing `data.url`.
- **Failure modes:** tmpfiles downtime, response shape changes.

#### Node: ğŸ’¾ Store Avatar URL
- **Type / role:** Code â€“ converts tmpfiles â€œviewâ€ URL to a direct download form:
  - `http://tmpfiles.org/{id}/{name}` â†’ `https://tmpfiles.org/dl/{id}/{name}`
- **Output:** sets `avatar_image_url`.
- **Failure modes:** regex mismatch if tmpfiles response format changes.

#### Node: ğŸ”Š Generate Audio (ElevenLabs)
- **Type / role:** HTTP Request â€“ text-to-speech.
- **Request:**
  - POST `https://api.elevenlabs.io/v1/text-to-speech/{{$json.voice_id}}`
  - JSON body includes `text: $json.script_audio`, model `eleven_multilingual_v2`
  - Response format set to **file**, stored in binary property `audio`
  - Headers: `xi-api-key`, `Accept: audio/mpeg`
- **Failure modes:** 401/429, unsupported voice ID, content rejection, long text limits.

#### Node: ğŸµ Convert Audio
- **Type / role:** Code â€“ normalizes the binary field to `audio_mp3` and restores JSON from the correct upstream branch.
- **Notable logic:** Tries to fetch prior JSON from nodes in priority:
  1) `ğŸ’¾ Store Avatar URL`
  2) `ğŸ“¸ Use Custom Avatar URL`
  3) `ğŸ–¼ï¸ Has Custom Avatar URL?`
- **Output:** binary `audio_mp3` with filename `voiceover.mp3`.
- **Failure modes:**
  - If node names change, the `$('node name')` lookups fail.
  - If ElevenLabs node output property name changes, `item.binary.audio` might be missing.

#### Node: â˜ï¸ Upload Audio
- **Type / role:** HTTP Request â€“ uploads `audio_mp3` to tmpfiles.
- **Failure modes:** same as avatar upload.

#### Node: ğŸ’¾ Store Audio URL
- **Type / role:** Code â€“ converts tmpfiles URL to `https://tmpfiles.org/dl/...` and sets `audio_url`.
- **Failure modes:** same regex dependency.

#### Node: ğŸ¬ Generate Talking Head (VEED)
- **Type / role:** VEED node (`n8n-nodes-veed.veed`) â€“ generates lip-synced avatar video.
- **Key parameters:**
  - `audioUrl: {{$json.audio_url}}`
  - `imageUrl: {{$json.avatar_image_url}}`
  - `resolution: {{$json.video_resolution}}` (note config says VEED supports 720p)
  - `aspectRatio: 9:16` (vertical)
  - Timeout option: 60 seconds
- **Failure modes:**
  - Invalid/expired asset URLs (tmpfiles is temporary)
  - VEED API errors, timeouts (60s may be short for some renders)
  - Resolution constraints (config comment: VEED only supports 720p)

#### Node: ğŸ“¹ Extract VEED Video URL
- **Type / role:** Code â€“ extracts a video URL from multiple possible response shapes:
  - `video.url`, `output.video_url`, `videoUrl`, or `url`
- **Output:** `avatar_video_url` + `asset_type: "avatar_video"`
- **Failure modes:** VEED response schema not matching any checked fields â†’ `avatar_video_url` becomes empty, breaking downstream composition.

---

### Block 4B â€” Slide Image Generation (FAL Flux Pro)
**Overview:** Turns Claude slide prompts into actual 1920Ã—1080 slide images, in parallel per slide; then aggregates and sorts them for composition.  
**Nodes involved:**  
- ğŸ“‘ Expand Slides  
- ğŸ–¼ï¸ Generate Slide (FAL)  
- ğŸ“¸ Extract Slide URL  
- ğŸ“š Aggregate Slides  
- ğŸ“Š Format Slides

#### Node: ğŸ“‘ Expand Slides
- **Type / role:** Code â€“ maps `slides[]` into multiple items so each can be generated independently.
- **Output fields:** `current_slide`, `slide_index`, plus the full base data copied along.
- **Failure modes:** `slides` missing or not an array â†’ generates 0 items; downstream will have no slides.

#### Node: ğŸ–¼ï¸ Generate Slide (FAL)
- **Type / role:** HTTP Request â€“ calls FAL Flux Pro.
- **Request:**
  - POST `https://fal.run/fal-ai/flux-pro/v1.1`
  - prompt: `current_slide.image_prompt`
  - image size: 1920Ã—1080
  - `num_images: 1`
  - Auth: `Authorization: Key {{$json.fal_api_key}}`
- **Batching option:** enabled with batchSize 1 (effectively per-item; still allows n8n batching behavior).
- **Failure modes:** invalid key, content safety blocks, rate limits, slow generation.

#### Node: ğŸ“¸ Extract Slide URL
- **Type / role:** Code â€“ pairs each FAL response to the corresponding expanded slide item, extracts an image URL.
- **Extraction logic:** checks `images[0].url`, `image.url`, `output[0]`.
- **Also sets:** `duration_seconds` = `current_slide.duration_seconds` OR `seconds_per_slide` OR 9.
- **Failure modes:**
  - If batching/concurrency changes item ordering, index-based pairing can mismatch slides.
  - No URL found â†’ throws error and stops execution.

#### Node: ğŸ“š Aggregate Slides
- **Type / role:** Aggregate node â€“ aggregates all incoming slide items into one field `all_slides_data`.
- **Mode:** â€œaggregate all item dataâ€.
- **Failure modes:** If no slide items arrive, output may be empty/undefined, causing format step issues.

#### Node: ğŸ“Š Format Slides
- **Type / role:** Code â€“ sorts aggregated slides by `slide_index` and outputs `slides_with_urls`.
- **Output:** `{ slides_with_urls: [...], asset_type: "all_slides" }`
- **Failure modes:** missing indices â†’ sort fallback uses 0; may reorder incorrectly if indices absent.

---

### Block 5 â€” Merge + Creatomate Composition + Render Polling
**Overview:** Combines avatar video URL and ordered slides into a Creatomate â€œelementsâ€ timeline, triggers a render, then polls until status is `succeeded`.  
**Nodes involved:**  
- ğŸ”— Merge Avatar + Slides  
- ğŸ“¦ Prepare Creatomate Request  
- ğŸ¬ Render Video (Creatomate)  
- ğŸ“Š Extract Render Info  
- â³ Wait for Render  
- ğŸ” Check Render Status  
- ğŸ“‹ Process Status  
- âœ… Render Done?

#### Node: ğŸ”— Merge Avatar + Slides
- **Type / role:** Merge node â€“ combines streams.
- **Mode:** `combine` with `combineAll` (creates a combined set containing both branch outputs).
- **Inputs:**  
  - Input 0: avatar branch item (`avatar_video_url`)
  - Input 1: slides branch item (`slides_with_urls`)
- **Failure modes:**
  - If either branch doesnâ€™t produce an item, the merge/combineAll behavior can lead to missing data downstream.

#### Node: ğŸ“¦ Prepare Creatomate Request
- **Type / role:** Code â€“ builds the full Creatomate RenderScript `elements`.
- **Key behaviors:**
  - Detects which combined items contain `avatar_video_url` and which contain `slides_with_urls`.
  - Uses `estimated_duration` to compute `durationPerSlide`.
  - Builds `slideElements` (track 1 images with optional fade transitions).
  - Optional background support:
    - `background_type: gradient` â†’ adds a `shape` element with `fill_color` gradient stops
    - `background_type: url` â†’ adds a full-canvas background image
  - Layout logic:
    - **With background:** slides in a rounded composition (74% width) + avatar video (20% width) with margins
    - **No background:** full-bleed slides (78%) + avatar (22%) without rounded clipping
- **Output:** `creatomate_elements`, `total_duration`, `num_slides`, etc.
- **Failure modes:**
  - If `avatarVideoUrl` is empty, Creatomate may error or render without presenter.
  - If slide URLs are empty/unreachable, render fails.
  - Gradient stop calculation can divide by zero if only one color is provided (the code uses `(min(colors.length,5)-1)`; with length 1, this becomes 0). This is a real edge case if user sets background gradient array with a single color.

#### Node: ğŸ¬ Render Video (Creatomate)
- **Type / role:** HTTP Request â€“ starts a render job.
- **Request:**
  - POST `https://api.creatomate.com/v2/renders`
  - Output: mp4, 1920Ã—1080, 60 fps, H.264 high profile, CRF 18
  - Body includes `elements` as JSON string of `creatomate_elements`
  - Auth: `Bearer {{$json.creatomate_api_key}}`
- **Failure modes:** invalid key, invalid element schema, rate limits, render queue delays.

#### Node: ğŸ“Š Extract Render Info
- **Type / role:** Code â€“ normalizes Creatomate response shape (array or object) into:
  - `render_id`, `render_url`, `render_status`
- **Failure modes:** unexpected response format leads to empty `render_id`, breaking polling.

#### Node: â³ Wait for Render
- **Type / role:** Wait node â€“ pauses for 30 seconds before checking status.
- **Failure modes:** None typical; but increases total run time.

#### Node: ğŸ” Check Render Status
- **Type / role:** HTTP Request â€“ fetch render by ID.
- **Request:** GET `https://api.creatomate.com/v2/renders/{{$json.render_id}}`
- **Auth header:** reads key from `$('ğŸ“¦ Prepare Creatomate Request').item.json.creatomate_api_key`
- **Failure modes:**
  - If node name changes, credential lookup breaks.
  - Missing/empty `render_id`.
  - 404 if render ID invalid/expired.

#### Node: ğŸ“‹ Process Status
- **Type / role:** Code â€“ updates:
  - `render_status`
  - `final_video_url` (from `statusResponse.url`)
- **Failure modes:** If `url` not present until succeeded, may remain empty.

#### Node: âœ… Render Done?
- **Type / role:** IF â€“ checks `render_status == "succeeded"`.
- **True:** Download final video  
- **False:** loops back to Wait (poll every 30s)

---

### Block 6 â€” Output (Download â†’ Drive â†’ Sheets)
**Overview:** Retrieves the final MP4, stores it in Google Drive, then logs a record into Google Sheets and returns a final summary payload.  
**Nodes involved:**  
- â¬‡ï¸ Download Final Video  
- ğŸ“¤ Upload to Drive  
- âœ… Prepare Final Data  
- ğŸ“ Log to Sheets

#### Node: â¬‡ï¸ Download Final Video
- **Type / role:** HTTP Request â€“ downloads binary MP4 from `final_video_url`.
- **Response format:** file (binary).
- **Failure modes:** URL expired, 403/404, large file download issues.

#### Node: ğŸ“¤ Upload to Drive
- **Type / role:** Google Drive node â€“ uploads the downloaded binary to a specified folder.
- **Key configuration:**
  - File name: `topic` sanitized to underscores, truncated to 30 chars, plus timestamp.
  - Drive: â€œMy Driveâ€
  - Folder: set via `YOUR_GOOGLE_DRIVE_FOLDER_URL`
- **Credentials required:** Google Drive OAuth2 in n8n.
- **Failure modes:** OAuth not configured, folder URL invalid, insufficient permissions, file too large.

#### Node: âœ… Prepare Final Data
- **Type / role:** Code â€“ creates final structured output including Drive link and metadata (caption, script, theme, etc.).
- **Drive URL logic:** uses `webViewLink` or constructs `https://drive.google.com/file/d/{id}/view`.
- **Failure modes:** missing `id` in Drive response (rare).

#### Node: ğŸ“ Log to Sheets
- **Type / role:** Google Sheets node â€“ appends a row to `Sheet1`.
- **Configuration:**
  - Operation: append
  - Mapping: auto-map input data
  - Document: `YOUR_GOOGLE_SHEETS_URL`
- **Credentials required:** Google Sheets OAuth2 in n8n.
- **Failure modes:** permissions, wrong sheet name, auto-mapping mismatch, Sheets API quotas.

---

## 3. Summary Table

| Node Name | Node Type | Functional Role | Input Node(s) | Output Node(s) | Sticky Note |
|---|---|---|---|---|---|
| When clicking 'Execute workflow' | Manual Trigger | Entry point (manual run) | â€” | âš™ï¸ Workflow Configuration | ## How it works â€¦ (full note content applies to overall workflow) |
| âš™ï¸ Workflow Configuration | Code | Central config object (topic, keys, style, overrides) | When clicking 'Execute workflow' | ğŸ§  Build Claude Prompt | **1. Configuration** â€” Set your topic, API keys, voice, and slide style preferences |
| ğŸ§  Build Claude Prompt | Code | Builds strict JSON-output prompt for Claude | âš™ï¸ Workflow Configuration | ğŸ¤– Claude: Generate Content | **2. AI script and slides** â€” Claude generates voiceover script, slide prompts, avatar description, and social caption |
| ğŸ¤– Claude: Generate Content | HTTP Request | Calls Anthropic to generate script/slide prompts/caption | ğŸ§  Build Claude Prompt | ğŸ“‹ Parse Claude Response | **2. AI script and slides** â€” Claude generates voiceover script, slide prompts, avatar description, and social caption |
| ğŸ“‹ Parse Claude Response | Code | Parses/validates Claude JSON; computes durations; selects voice | ğŸ¤– Claude: Generate Content | ğŸ”€ Split into Flows | **2. AI script and slides** â€” Claude generates voiceover script, slide prompts, avatar description, and social caption |
| ğŸ”€ Split into Flows | Code | Duplicates item into avatar + slides flows | ğŸ“‹ Parse Claude Response | ğŸ”€ Avatar Flow?, ğŸ”€ Slides Flow? | ## How it works â€¦ (parallel avatar + slides) |
| ğŸ”€ Avatar Flow? | IF | Route only avatar item | ğŸ”€ Split into Flows | ğŸ–¼ï¸ Has Custom Avatar URL? | ### Avatar and audio generation â€¦ |
| ğŸ–¼ï¸ Has Custom Avatar URL? | IF | Decide custom avatar URL vs OpenAI generation | ğŸ”€ Avatar Flow? | ğŸ“¸ Use Custom Avatar URL, ğŸ¨ Generate Avatar (OpenAI) | **3. Avatar generation** â€” Creates or uses custom avatar image via OpenAI, uploads to temporary storage |
| ğŸ“¸ Use Custom Avatar URL | Code | Set avatar_image_url from provided URL | ğŸ–¼ï¸ Has Custom Avatar URL? (true) | ğŸ”Š Generate Audio (ElevenLabs) | **3. Avatar generation** â€” Creates or uses custom avatar image via OpenAI, uploads to temporary storage |
| ğŸ¨ Generate Avatar (OpenAI) | HTTP Request | Generate avatar portrait image (base64) | ğŸ–¼ï¸ Has Custom Avatar URL? (false) | ğŸ“¸ Extract Avatar Image | **3. Avatar generation** â€” Creates or uses custom avatar image via OpenAI, uploads to temporary storage |
| ğŸ“¸ Extract Avatar Image | Code | Convert OpenAI base64 to binary PNG | ğŸ¨ Generate Avatar (OpenAI) | â˜ï¸ Upload Avatar Image | **3. Avatar generation** â€” Creates or uses custom avatar image via OpenAI, uploads to temporary storage |
| â˜ï¸ Upload Avatar Image | HTTP Request | Upload avatar PNG to tmpfiles | ğŸ“¸ Extract Avatar Image | ğŸ’¾ Store Avatar URL | **3. Avatar generation** â€” Creates or uses custom avatar image via OpenAI, uploads to temporary storage |
| ğŸ’¾ Store Avatar URL | Code | Convert tmpfiles URL to direct download; store avatar_image_url | â˜ï¸ Upload Avatar Image | ğŸ”Š Generate Audio (ElevenLabs) | **3. Avatar generation** â€” Creates or uses custom avatar image via OpenAI, uploads to temporary storage |
| ğŸ”Š Generate Audio (ElevenLabs) | HTTP Request | TTS voiceover â†’ binary mp3 | ğŸ’¾ Store Avatar URL / ğŸ“¸ Use Custom Avatar URL | ğŸµ Convert Audio | ### Avatar and audio generation â€¦ |
| ğŸµ Convert Audio | Code | Rename binary prop; restore JSON from correct branch | ğŸ”Š Generate Audio (ElevenLabs) | â˜ï¸ Upload Audio | ### Avatar and audio generation â€¦ |
| â˜ï¸ Upload Audio | HTTP Request | Upload mp3 to tmpfiles | ğŸµ Convert Audio | ğŸ’¾ Store Audio URL | ### Avatar and audio generation â€¦ |
| ğŸ’¾ Store Audio URL | Code | Convert tmpfiles URL; store audio_url | â˜ï¸ Upload Audio | ğŸ¬ Generate Talking Head (VEED) | ### Avatar and audio generation â€¦ |
| ğŸ¬ Generate Talking Head (VEED) | VEED | Lip-sync avatar image + audio into vertical video | ğŸ’¾ Store Audio URL | ğŸ“¹ Extract VEED Video URL | **4. Talking head** â€” VEED creates lip-synced video from avatar and audio |
| ğŸ“¹ Extract VEED Video URL | Code | Normalize VEED response into avatar_video_url | ğŸ¬ Generate Talking Head (VEED) | ğŸ”— Merge Avatar + Slides | **4. Talking head** â€” VEED creates lip-synced video from avatar and audio |
| ğŸ”€ Slides Flow? | IF | Route only slides item | ğŸ”€ Split into Flows | ğŸ“‘ Expand Slides | ### Slide image generation â€¦ |
| ğŸ“‘ Expand Slides | Code | Fan-out slides[] into per-slide items | ğŸ”€ Slides Flow? | ğŸ–¼ï¸ Generate Slide (FAL) | ### Slide image generation â€¦ |
| ğŸ–¼ï¸ Generate Slide (FAL) | HTTP Request | Generate each slide image via FAL Flux Pro | ğŸ“‘ Expand Slides | ğŸ“¸ Extract Slide URL | ### Slide image generation â€¦ |
| ğŸ“¸ Extract Slide URL | Code | Extract URL from FAL response; keep slide_index | ğŸ–¼ï¸ Generate Slide (FAL) | ğŸ“š Aggregate Slides | ### Slide image generation â€¦ |
| ğŸ“š Aggregate Slides | Aggregate | Combine all slide items into one payload | ğŸ“¸ Extract Slide URL | ğŸ“Š Format Slides | ### Slide image generation â€¦ |
| ğŸ“Š Format Slides | Code | Sort slides; output slides_with_urls | ğŸ“š Aggregate Slides | ğŸ”— Merge Avatar + Slides | ### Slide image generation â€¦ |
| ğŸ”— Merge Avatar + Slides | Merge | Combine avatar_video_url + slides_with_urls | ğŸ“¹ Extract VEED Video URL, ğŸ“Š Format Slides | ğŸ“¦ Prepare Creatomate Request | **5. Video composition** â€” Creatomate merges slides as background with talking head overlay, then polls until render completes |
| ğŸ“¦ Prepare Creatomate Request | Code | Build Creatomate elements timeline and layout | ğŸ”— Merge Avatar + Slides | ğŸ¬ Render Video (Creatomate) | **5. Video composition** â€” Creatomate merges slides as background with talking head overlay, then polls until render completes |
| ğŸ¬ Render Video (Creatomate) | HTTP Request | Start Creatomate render | ğŸ“¦ Prepare Creatomate Request | ğŸ“Š Extract Render Info | **5. Video composition** â€” Creatomate merges slides as background with talking head overlay, then polls until render completes |
| ğŸ“Š Extract Render Info | Code | Capture render_id/status/url | ğŸ¬ Render Video (Creatomate) | â³ Wait for Render | **5. Video composition** â€” Creatomate merges slides as background with talking head overlay, then polls until render completes |
| â³ Wait for Render | Wait | Delay between status polls (30s) | ğŸ“Š Extract Render Info, âœ… Render Done? (false) | ğŸ” Check Render Status | **5. Video composition** â€” Creatomate merges slides as background with talking head overlay, then polls until render completes |
| ğŸ” Check Render Status | HTTP Request | Query Creatomate render by ID | â³ Wait for Render | ğŸ“‹ Process Status | **5. Video composition** â€” Creatomate merges slides as background with talking head overlay, then polls until render completes |
| ğŸ“‹ Process Status | Code | Update render_status and final_video_url | ğŸ” Check Render Status | âœ… Render Done? | **5. Video composition** â€” Creatomate merges slides as background with talking head overlay, then polls until render completes |
| âœ… Render Done? | IF | Loop until `succeeded` | ğŸ“‹ Process Status | â¬‡ï¸ Download Final Video (true), â³ Wait for Render (false) | **5. Video composition** â€” Creatomate merges slides as background with talking head overlay, then polls until render completes |
| â¬‡ï¸ Download Final Video | HTTP Request | Download final MP4 binary | âœ… Render Done? (true) | ğŸ“¤ Upload to Drive | **6. Output** â€” Downloads final video, uploads to Google Drive, and logs results to Google Sheets |
| ğŸ“¤ Upload to Drive | Google Drive | Store MP4 in Drive folder | â¬‡ï¸ Download Final Video | âœ… Prepare Final Data | **6. Output** â€” Downloads final video, uploads to Google Drive, and logs results to Google Sheets |
| âœ… Prepare Final Data | Code | Assemble final response object (Drive URL + metadata) | ğŸ“¤ Upload to Drive | ğŸ“ Log to Sheets | **6. Output** â€” Downloads final video, uploads to Google Drive, and logs results to Google Sheets |
| ğŸ“ Log to Sheets | Google Sheets | Append run metadata to a spreadsheet | âœ… Prepare Final Data | â€” | **6. Output** â€” Downloads final video, uploads to Google Drive, and logs results to Google Sheets |

---

## 4. Reproducing the Workflow from Scratch

1) **Create a new workflow**
- Name it: â€œCreate AI screencast videos with VEED and automated slidesâ€
- Keep it inactive until credentials are set.

2) **Add Trigger**
- Add **Manual Trigger** node: `When clicking 'Execute workflow'`.

3) **Add Configuration (Code)**
- Add **Code** node: `âš™ï¸ Workflow Configuration`
- Return a single JSON object containing:
  - content fields (`topic`, `intention`, `brand_name`, `target_audience`, `trending_hashtags`)
  - `slide_style`, `seconds_per_slide`, `background`
  - API keys: `anthropic_api_key`, `openai_api_key`, `elevenlabs_api_key`, `creatomate_api_key`, `fal_api_key`
  - `voice_selection`
  - optional avatar/script overrides (`custom_avatar_description`, `custom_avatar_image_url`, `custom_script`)
- Connect: Manual Trigger â†’ Configuration.

4) **Build Claude Prompt (Code)**
- Add **Code** node: `ğŸ§  Build Claude Prompt`
- Implement:
  - slide style lookup table
  - dynamic instructions based on presence of custom script/avatar
  - strict JSON-only output requirement
- Output fields must include at least: `claude_prompt` plus config passthrough.
- Connect: Configuration â†’ Build Claude Prompt.

5) **Call Anthropic (HTTP Request)**
- Add **HTTP Request** node: `ğŸ¤– Claude: Generate Content`
- Method: POST
- URL: `https://api.anthropic.com/v1/messages`
- Headers:
  - `x-api-key` = `{{$json.anthropic_api_key}}`
  - `anthropic-version` = `2023-06-01`
  - `Content-Type` = `application/json`
- Body (JSON):
  - model: `claude-sonnet-4-20250514`
  - max_tokens: 3000
  - messages: user content set to the generated prompt
- Connect: Build Claude Prompt â†’ Claude node.

6) **Parse/Normalize Claude Output (Code)**
- Add **Code** node: `ğŸ“‹ Parse Claude Response`
- Responsibilities:
  - extract `content[0].text`
  - strip ``` fences if present
  - JSON.parse with fallback defaults
  - select ElevenLabs `voice_id`
  - compute `estimated_duration`, `num_slides`, `duration_per_slide`
  - normalize `slides[]`, `script_audio`, `avatar_prompt`
  - interpret `background` into `background_type/background_value`
- Connect: Claude â†’ Parse.

7) **Split into parallel flows (Code + IF routers)**
- Add **Code** node: `ğŸ”€ Split into Flows` â†’ output two items with `flow: avatar` and `flow: slides`.
- Add **IF** node: `ğŸ”€ Avatar Flow?` condition `{{$json.flow}} equals "avatar"`.
- Add **IF** node: `ğŸ”€ Slides Flow?` condition `{{$json.flow}} equals "slides"`.
- Connect: Parse â†’ Split.
- Connect: Split â†’ Avatar Flow? and Split â†’ Slides Flow? (same output to both routers).

---

### Avatar branch (talking head)

8) **Custom avatar URL decision**
- Add **IF** node: `ğŸ–¼ï¸ Has Custom Avatar URL?` condition `{{$json.has_custom_avatar_url}} equals true`.
- Connect: Avatar Flow? (true) â†’ Has Custom Avatar URL?

9) **If TRUE: use provided URL**
- Add **Code** node: `ğŸ“¸ Use Custom Avatar URL` setting `avatar_image_url = custom_avatar_image_url`.
- Connect: Has Custom Avatar URL? (true) â†’ Use Custom Avatar URL.

10) **If FALSE: generate avatar via OpenAI**
- Add **HTTP Request** node: `ğŸ¨ Generate Avatar (OpenAI)`
  - POST `https://api.openai.com/v1/images/generations`
  - Header `Authorization: Bearer {{$json.openai_api_key}}`
  - JSON: model `gpt-image-1`, prompt `{{$json.avatar_prompt}}`, size `1024x1536`, quality `high`
- Add **Code** node: `ğŸ“¸ Extract Avatar Image` â†’ convert `b64_json` to binary PNG field `avatar_image`.
- Add **HTTP Request** node: `â˜ï¸ Upload Avatar Image` (multipart upload to `https://tmpfiles.org/api/v1/upload`, file field from `avatar_image`).
- Add **Code** node: `ğŸ’¾ Store Avatar URL` â†’ convert tmpfiles URL to `/dl/` and set `avatar_image_url`.
- Connect: Has Custom Avatar URL? (false) â†’ Generate Avatar â†’ Extract Avatar Image â†’ Upload Avatar Image â†’ Store Avatar URL.

11) **Generate voiceover (ElevenLabs)**
- Add **HTTP Request** node: `ğŸ”Š Generate Audio (ElevenLabs)`
  - POST `https://api.elevenlabs.io/v1/text-to-speech/{{$json.voice_id}}`
  - Headers: `xi-api-key: {{$json.elevenlabs_api_key}}`, `Accept: audio/mpeg`, `Content-Type: application/json`
  - Body includes `text: {{$json.script_audio}}` and voice settings
  - Response: **File**; output binary property name `audio`
- Connect:
  - Use Custom Avatar URL â†’ Generate Audio
  - Store Avatar URL â†’ Generate Audio

12) **Normalize and upload audio**
- Add **Code** node: `ğŸµ Convert Audio`:
  - move binary `audio` to `audio_mp3` with filename `voiceover.mp3`
  - restore JSON from the appropriate upstream node (be careful if you rename nodes)
- Add **HTTP Request** node: `â˜ï¸ Upload Audio` to tmpfiles (multipart; file from `audio_mp3`)
- Add **Code** node: `ğŸ’¾ Store Audio URL` convert to `/dl/`, store `audio_url`
- Connect: Generate Audio â†’ Convert Audio â†’ Upload Audio â†’ Store Audio URL.

13) **Generate VEED talking head**
- Add **VEED** node: `ğŸ¬ Generate Talking Head (VEED)`
  - audioUrl: `{{$json.audio_url}}`
  - imageUrl: `{{$json.avatar_image_url}}`
  - resolution: `{{$json.video_resolution}}` (set config to `720p`)
  - aspect ratio: `9:16`
  - timeout: 60s (increase if needed)
- Add **Code** node: `ğŸ“¹ Extract VEED Video URL` to set `avatar_video_url`.
- Connect: Store Audio URL â†’ VEED â†’ Extract VEED Video URL.

---

### Slides branch

14) **Expand slides into items**
- Add **Code** node: `ğŸ“‘ Expand Slides` mapping `slides[]` to multiple items with `current_slide` and `slide_index`.
- Connect: Slides Flow? (true) â†’ Expand Slides.

15) **Generate slide images via FAL**
- Add **HTTP Request** node: `ğŸ–¼ï¸ Generate Slide (FAL)`
  - POST `https://fal.run/fal-ai/flux-pro/v1.1`
  - Header: `Authorization: Key {{$json.fal_api_key}}`
  - JSON body: prompt `{{$json.current_slide.image_prompt}}`, size 1920Ã—1080, num_images 1
- Add **Code** node: `ğŸ“¸ Extract Slide URL` to extract the resulting image URL and keep ordering fields.
- Connect: Expand Slides â†’ Generate Slide â†’ Extract Slide URL.

16) **Aggregate and sort**
- Add **Aggregate** node: `ğŸ“š Aggregate Slides` to aggregate all item data into `all_slides_data`.
- Add **Code** node: `ğŸ“Š Format Slides` to sort by `slide_index` and output `slides_with_urls`.
- Connect: Extract Slide URL â†’ Aggregate Slides â†’ Format Slides.

---

### Merge + Creatomate render + polling

17) **Merge branches**
- Add **Merge** node: `ğŸ”— Merge Avatar + Slides`
  - Mode: Combine
  - Combine by: Combine All
- Connect:
  - Extract VEED Video URL â†’ Merge (input 0)
  - Format Slides â†’ Merge (input 1)

18) **Prepare Creatomate elements**
- Add **Code** node: `ğŸ“¦ Prepare Creatomate Request`
  - Build `creatomate_elements` using slide images and avatar video URL
  - Respect `background_type/background_value` for optional background
  - Use `estimated_duration` to set durations
- Connect: Merge â†’ Prepare Creatomate Request.

19) **Start Creatomate render**
- Add **HTTP Request** node: `ğŸ¬ Render Video (Creatomate)`
  - POST `https://api.creatomate.com/v2/renders`
  - Header: `Authorization: Bearer {{$json.creatomate_api_key}}`
  - Body includes encoding settings and `elements: {{$json.creatomate_elements}}`
- Add **Code** node: `ğŸ“Š Extract Render Info` to set `render_id`, `render_status`, `render_url`.
- Connect: Prepare Creatomate Request â†’ Render Video â†’ Extract Render Info.

20) **Polling loop**
- Add **Wait** node: `â³ Wait for Render` amount 30 seconds.
- Add **HTTP Request** node: `ğŸ” Check Render Status`
  - GET `https://api.creatomate.com/v2/renders/{{$json.render_id}}`
  - Auth header must use your API key (either from current item or referenced node)
- Add **Code** node: `ğŸ“‹ Process Status` to set `render_status` and `final_video_url`.
- Add **IF** node: `âœ… Render Done?` condition `{{$json.render_status}} equals "succeeded"`.
- Connect:
  - Extract Render Info â†’ Wait â†’ Check Render Status â†’ Process Status â†’ Render Done?
  - Render Done? (false) â†’ Wait (loop)

---

### Output

21) **Download final MP4**
- Add **HTTP Request** node: `â¬‡ï¸ Download Final Video`
  - URL: `{{$json.final_video_url}}`
  - Response: File
- Connect: Render Done? (true) â†’ Download Final Video.

22) **Upload to Google Drive**
- Add **Google Drive** node: `ğŸ“¤ Upload to Drive`
  - Operation: Upload
  - Binary property: the downloaded file
  - Folder: set your target folder
  - Filename expression based on topic + timestamp
- **Credentials:** configure Google Drive OAuth2 in n8n and select it in node.
- Connect: Download Final Video â†’ Upload to Drive.

23) **Prepare final metadata**
- Add **Code** node: `âœ… Prepare Final Data` to output a summary JSON including Drive link, script, caption, etc.
- Connect: Upload to Drive â†’ Prepare Final Data.

24) **Log to Google Sheets**
- Add **Google Sheets** node: `ğŸ“ Log to Sheets`
  - Operation: Append
  - Spreadsheet: your document
  - Sheet name: `Sheet1` (or adjust)
  - Mapping: auto-map from `âœ… Prepare Final Data`
- **Credentials:** Google Sheets OAuth2 in n8n.
- Connect: Prepare Final Data â†’ Log to Sheets.

---

## 5. General Notes & Resources

| Note Content | Context or Link |
|---|---|
| This workflow generates professional screencast-style videos with a talking head avatar and AI-generated slides; it runs two parallel processes (avatar path + slides path), then composites in Creatomate, uploads to Drive, and logs to Sheets. | Sticky note: â€œHow it worksâ€ |
| Setup: add API keys in the Configuration node (Anthropic, OpenAI, ElevenLabs, FAL.ai, Creatomate). | Sticky note: â€œHow it worksâ€ |
| Setup: configure n8n credentials for Google Drive OAuth2 and Google Sheets OAuth2; update folder URL and Sheets URL in output nodes. | Sticky note: â€œHow it worksâ€ |
| Avatar/audio branch: ElevenLabs generates speech, VEED lip-syncs to produce a vertical presenter video. | Sticky note: â€œAvatar and audio generationâ€ |
| Slides branch: FAL Flux Pro generates 5â€“7 high-quality 16:9 slide images from Claude prompts. | Sticky note: â€œSlide image generationâ€ |
| VEED resolution constraint mentioned in config: â€œVEED only supports 720pâ€. | Configuration code comments |
| Temporary hosting uses tmpfiles.org; links may expire, affecting VEED/Creatomate steps. Consider replacing with durable storage (e.g., S3/GCS) for production. | Workflow design implication |

disclaimer Le texte fourni provient exclusivement dâ€™un workflow automatisÃ© rÃ©alisÃ© avec n8n, un outil dâ€™intÃ©gration et dâ€™automatisation. Ce traitement respecte strictement les politiques de contenu en vigueur et ne contient aucun Ã©lÃ©ment illÃ©gal, offensant ou protÃ©gÃ©. Toutes les donnÃ©es manipulÃ©es sont lÃ©gales et publiques.