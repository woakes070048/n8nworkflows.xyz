Run AI-powered market research with Groq, OpenAI, Documentero and Gmail

https://n8nworkflows.xyz/workflows/run-ai-powered-market-research-with-groq--openai--documentero-and-gmail-12236


# Run AI-powered market research with Groq, OpenAI, Documentero and Gmail

## 1. Workflow Overview

**Purpose:**  
This workflow turns a user’s product idea/research topic (submitted via n8n Chat) into a **PM-ready market discovery memo**, generated by multiple AI “specialist agents” running in parallel, then synthesized into one narrative, converted into a document (Documentero), and emailed via Gmail.

**Typical use cases**
- Early-stage product discovery / validation for new ideas
- Directional market sizing and trend scanning (TAM/SAM/SOM ranges)
- Competitive landscaping and substitutes mapping
- Summarized decision memo for internal sharing

### 1.1 Input Reception & Orchestration Trigger
Receives a chat message as the single entry point and passes it to the Planner Agent.

### 1.2 Research Planning (Planner Agent)
The planner converts the idea into a structured plan: objective, tasks for market/customer/competition, and assumptions.

### 1.3 Parallel Specialist Research (3 agents)
Three research agents run concurrently using the planner’s structured output:
- Customer Insights Agent
- Market Scan Agent
- Competitor Insights Agent

### 1.4 Consolidation & Synthesis
All three specialist outputs are merged and synthesized into one structured decision memo (JSON).

### 1.5 Document Generation & Email Delivery
The memo is converted into HTML, passed to Documentero for document generation (and/or emailing), then delivered via Gmail with an attachment.

---

## 2. Block-by-Block Analysis

### Block 1 — User Input & Trigger
**Overview:** Captures the user’s research topic/product idea from chat and starts the workflow.  
**Nodes involved:**  
- When chat message received

#### Node: When chat message received
- **Type / Role:** `@n8n/n8n-nodes-langchain.chatTrigger` — entry point for chat-driven executions.
- **Key configuration:**
  - **Response Mode:** `lastNode` (the final node’s output is returned to the chat client).
  - **alwaysOutputData:** enabled (helps avoid empty outputs).
- **Key data/variables:**
  - Provides `{{$json.chatInput}}` used later by the Planner Agent.
- **Connections:**
  - **Output →** Planner Agent (main)
- **Failure/edge cases:**
  - If chat message payload is missing `chatInput`, planner prompt expressions referencing it will produce empty/invalid plans.
  - Response mode depends on the final node producing a response-compatible output (here the workflow ends in email, so chat response may not be meaningful unless the last node returns something useful).

**Sticky note (applies to this block):**  
“## User Input & Trigger … triggered manually via a chat message … easy to test and iterate during discovery.”

---

### Block 2 — Research Planning (Planner Agent)
**Overview:** The planner agent turns the raw idea into a structured plan with tasks and assumptions, enforcing a strict JSON structure.  
**Nodes involved:**  
- Planner Agent  
- Simple Memory  
- Groq Chat Model1  
- Structured Output Parser1

#### Node: Simple Memory
- **Type / Role:** `memoryBufferWindow` — provides conversational context memory to the Planner Agent.
- **Key configuration:** default buffer window settings (not customized in this JSON).
- **Connections:**
  - **ai_memory →** Planner Agent
- **Failure/edge cases:**
  - Memory growth/retention depends on node defaults; can introduce context bleed if multiple chats reuse the same session context in some deployments.

#### Node: Groq Chat Model1
- **Type / Role:** `lmChatGroq` — LLM provider for the Planner Agent.
- **Key configuration:**
  - **Model:** `qwen/qwen3-32b`
- **Connections:**
  - **ai_languageModel →** Planner Agent
- **Failure/edge cases:**
  - Groq credential/config missing will fail authentication.
  - Model availability changes on Groq side can break runs; consider pinning to stable model names.

#### Node: Structured Output Parser1
- **Type / Role:** `outputParserStructured` — enforces that the Planner Agent outputs JSON matching a schema.
- **Key configuration:**
  - Uses a JSON example schema with keys:
    - `research_idea`, `research_objective`, `market_task`, `competitor_task`, `customer_task`, `assumptions`
- **Connections:**
  - **ai_outputParser →** Planner Agent
- **Failure/edge cases:**
  - If the LLM outputs invalid JSON (smart quotes, trailing commas, extra commentary), parsing fails.

#### Node: Planner Agent
- **Type / Role:** `@n8n/n8n-nodes-langchain.agent` — orchestrator that creates the research plan and assigns tasks.
- **Key configuration choices (interpreted):**
  - Prompt includes role definition (“Senior Product Manager leading market discovery”).
  - Takes user idea from `{{$json.chatInput}}`.
  - Outputs **STRICT JSON** with defined keys.
  - **System message:** instructs the planner to only plan and delegate; not perform research itself.
  - **hasOutputParser:** enabled (Structured Output Parser1 attached).
- **Connections:**
  - **Input ←** When chat message received
  - **ai_memory ←** Simple Memory
  - **ai_languageModel ←** Groq Chat Model1
  - **ai_outputParser ←** Structured Output Parser1
  - **Output →** Market Scan Agent, Competitor Insights Agent, Customer Insights Agent (three parallel main connections)
- **Failure/edge cases:**
  - Planner output schema mismatch breaks all downstream expressions like `{{$json.output.market_task}}`.
  - If Planner returns empty tasks, downstream agents will produce low-quality or mis-scoped outputs.

**Sticky note (applies to this block):**  
“## Research Planning (Planner Agent) … defines scope … translates idea into clear research tasks and assumptions … structured and consistent inputs.”

---

### Block 3 — Parallel Market Research Agents
**Overview:** Runs three specialist agents in parallel; each receives the planner output and returns structured findings.  
**Nodes involved:**  
- Customer Insights Agent, Simple Memory1, Groq Chat Model2, Structured Output Parser2  
- Market Scan Agent, Simple Memory2, Groq Chat Model3, Structured Output Parser3  
- Competitor Insights Agent, Simple Memory3, Groq Chat Model4, Structured Output Parser4

#### Customer sub-stream

##### Node: Simple Memory1
- **Type / Role:** memory for Customer Insights Agent.
- **Connections:** **ai_memory →** Customer Insights Agent
- **Edge cases:** same considerations as other memory nodes.

##### Node: Groq Chat Model2
- **Type / Role:** Groq LLM for customer research.
- **Model:** `moonshotai/kimi-k2-instruct-0905`
- **Connections:** **ai_languageModel →** Customer Insights Agent
- **Edge cases:** credential/model availability.

##### Node: Structured Output Parser2
- **Type / Role:** structured output enforcement for customer insights.
- **Schema:** expects:
  - `customer_insights.target_customer_segments[]`
  - `core_problems_ranked[]`
  - `current_solutions_and_frustrations[]`
  - `jtbd_insight_statements[]`
- **Connections:** **ai_outputParser →** Customer Insights Agent
- **Edge cases:** agent prompt asks for “each output item starts as a separate paragraph”, which can conflict with strict array JSON if the model responds in prose; parser will fail if not valid JSON.

##### Node: Customer Insights Agent
- **Type / Role:** LangChain Agent specializing in inferred customer pains/segments from public sources.
- **Key expressions:**
  - Uses planner output:  
    - `{{$json.output.research_idea}}`, `{{$json.output.assumptions}}`, `{{$json.output.customer_task}}`
- **Connections:**
  - **Input ←** Planner Agent
  - **ai_memory ←** Simple Memory1
  - **ai_languageModel ←** Groq Chat Model2
  - **ai_outputParser ←** Structured Output Parser2
  - **Output →** Merge (input index 0)
- **Edge cases:**
  - If Planner Agent output is not under `$json.output` as expected (parser differences), these expressions will be undefined.
  - Public-source requirement is not actually enforced (no browsing tool); output quality depends on model behavior and prompting.

#### Market sub-stream

##### Node: Simple Memory2
- Memory for Market Scan Agent.
- **Connections:** **ai_memory →** Market Scan Agent

##### Node: Groq Chat Model3
- **Type / Role:** Groq LLM for market scanning.
- **Model:** `meta-llama/llama-4-maverick-17b-128e-instruct`
- **Connections:** **ai_languageModel →** Market Scan Agent

##### Node: Structured Output Parser3
- **Type / Role:** structured JSON enforcement for market scan.
- **Schema highlights:**
  - `output.market_definition` (in/out of scope, geographies, customer types, value chain)
  - `output.tam_sam_som` with numeric values, currency, assumptions
  - `growth_drivers[]`, `market_maturity`, macro/micro analyses, trends, risks
- **Connections:** **ai_outputParser →** Market Scan Agent
- **Edge cases:**
  - Numeric fields (`value`: 0) require the model to output numbers; strings like `"~$5B"` will fail schema parsing depending on parser strictness.

##### Node: Market Scan Agent
- **Type / Role:** market strategy analyst agent.
- **Key expressions:**
  - `{{$json.output.research_objective}}`, `{{$json.output.market_task}}`, `{{$json.output.research_idea}}`, `{{$json.output.assumptions}}`
- **Connections:**
  - **Input ←** Planner Agent
  - **ai_memory ←** Simple Memory2
  - **ai_languageModel ←** Groq Chat Model3
  - **ai_outputParser ←** Structured Output Parser3
  - **Output →** Merge (input index 1)
- **Edge cases:**
  - Prompt says “Always return the output in JSON format prescribed” but system message is malformed (“You are a helpful assistantAlways…”), which can slightly reduce compliance.

#### Competitor sub-stream

##### Node: Simple Memory3
- Memory for Competitor Insights Agent.
- **Connections:** **ai_memory →** Competitor Insights Agent

##### Node: Groq Chat Model4
- **Type / Role:** Groq LLM for competitor analysis.
- **Model:** `moonshotai/kimi-k2-instruct-0905`
- **Connections:** **ai_languageModel →** Competitor Insights Agent

##### Node: Structured Output Parser4
- **Type / Role:** structured JSON enforcement for competitors.
- **Schema highlights:**
  - `output.competitor_table[]` with `name`, offering, pricing, position, strengths[], weaknesses[]
  - `competitive_gaps[]`, `observed_patterns[]`
- **Connections:** **ai_outputParser →** Competitor Insights Agent
- **Edge cases:**
  - If competitors are unknown, model may invent; prompt does not explicitly forbid fabrication beyond “if public” pricing guidance.

##### Node: Competitor Insights Agent
- **Type / Role:** competitive intelligence agent.
- **Key expressions:**
  - `{{$json.output.research_idea}}`, `{{$json.output.competitor_task}}`, `{{$json.output.assumptions}}`
- **Connections:**
  - **Input ←** Planner Agent
  - **ai_memory ←** Simple Memory3
  - **ai_languageModel ←** Groq Chat Model4
  - **ai_outputParser ←** Structured Output Parser4
  - **Output →** Merge (input index 2)
- **Edge cases:**
  - If planner doesn’t clearly define competitor_task, output can drift (substitutes vs direct competitors).

**Sticky note (applies to this whole block):**  
“## Parallel Market Research Agents … run specialist research agents in parallel … reduce latency … each focuses on one dimension.”

---

### Block 4 — Insight Synthesis & Decision Memo
**Overview:** Combines the three parallel outputs and synthesizes them into a single decision memo JSON.  
**Nodes involved:**  
- Merge  
- Synthesis Agent  
- OpenAI Chat Model3  
- Simple Memory4

#### Node: Merge
- **Type / Role:** `n8n-nodes-base.merge` — fan-in aggregator for three branches.
- **Key configuration:**
  - **numberInputs:** 3 (expects exactly three incoming streams)
- **Connections:**
  - **Input ←** Customer Insights Agent (0), Market Scan Agent (1), Competitor Insights Agent (2)
  - **Output →** Synthesis Agent
- **Failure/edge cases:**
  - If any branch errors or outputs no items, merge behavior may produce fewer items or fail depending on execution; synthesis expects complete context.
  - Order/indexing matters—miswiring inputs changes the merged structure.

#### Node: OpenAI Chat Model3
- **Type / Role:** `lmChatOpenAi` — LLM used for synthesis (separate from Groq).
- **Key configuration:**
  - **Model:** `gpt-4.1-mini`
- **Connections:** **ai_languageModel →** Synthesis Agent
- **Failure/edge cases:**
  - OpenAI credentials missing/invalid; quota/rate limits.
  - If using n8n self-hosted, ensure OpenAI node package versions support `gpt-4.1-mini`.

#### Node: Simple Memory4
- **Type / Role:** memory for synthesis step.
- **Connections:** **ai_memory →** Synthesis Agent

#### Node: Synthesis Agent
- **Type / Role:** LangChain Agent that converts merged research inputs into a memo-like structure.
- **Key configuration choices:**
  - Prompt: “synthesize all research inputs: `{{$json.output}}` into a PM-ready decision memo.”
  - Output format: a single JSON object with `output` containing 6 sections (executive summary, market opportunity, etc.).
  - **Batching:** enabled with `batchSize: 3`, delay 10 seconds (intended to handle the three merged items).
  - **System message:** instructs to produce only 1 item as output.
- **Connections:**
  - **Input ←** Merge
  - **ai_languageModel ←** OpenAI Chat Model3
  - **ai_memory ←** Simple Memory4
  - **Output →** Format Data for Documentero
- **Failure/edge cases:**
  - The reference `{{$json.output}}` assumes each merged item has an `output` field; if one agent schema differs (e.g., Customer parser returns `customer_insights` instead), synthesis may miss it unless merge structure contains it elsewhere.
  - Without a structured output parser here, the agent may output invalid JSON; downstream Code node tries to parse if needed but only expects a specific shape.

**Sticky note (applies to this block):**  
“## Insight Synthesis & Decision Memo … consolidated … decision-ready discovery memo … highlights insights, risks, next steps.”

---

### Block 5 — Document Generation & Delivery
**Overview:** Converts the synthesized memo into HTML content, generates a document via Documentero, then emails it via Gmail.  
**Nodes involved:**  
- Format Data for Documentero  
- Documentero  
- Send a message

#### Node: Format Data for Documentero
- **Type / Role:** `n8n-nodes-base.code` — transforms the synthesis JSON into HTML sections for document generation.
- **Key logic (interpreted):**
  - Reads: `rawOutput = $input.first().json.output`
  - If `rawOutput` is a string (escaped JSON), it parses it and then uses `.output`.
  - Builds an HTML string in a fixed section order:
    1. executive_summary
    2. market_opportunity
    3. customer_problem
    4. competitive_landscape
    5. key_risks_and_open_questions
    6. recommendation_next_steps
  - Outputs one item with:
    - `research_content_html` (HTML string)
    - `title` (“Market Research Report”)
    - `generated_date` (YYYY-MM-DD)
- **Connections:**
  - **Input ←** Synthesis Agent
  - **Output →** Documentero
- **Failure/edge cases:**
  - If Synthesis Agent returns `{output: "...string..."}` but not JSON parseable, Code node throws: “Failed to parse Synthesis Agent output…”
  - If sections are missing or renamed, those sections are silently skipped (only adds sections when content exists).
  - HTML is naive (no escaping), so unexpected characters could break formatting.

#### Node: Documentero
- **Type / Role:** `n8n-nodes-preview-documentero.documentero` — generates a document and emails it (operation suggests both actions).
- **Key configuration:**
  - **Operation:** `generateAndEmail`
  - Credentials are present but unspecified in the JSON export (must be configured in n8n).
- **Connections:**
  - **Input ←** Format Data for Documentero
  - **Output →** Send a message (Gmail)
- **Failure/edge cases:**
  - Missing Documentero API key / template configuration will fail.
  - “generateAndEmail” may already email the document; this workflow additionally sends via Gmail, which can cause duplicate sends unless Documentero email is configured to a different recipient or disabled in template settings.

#### Node: Send a message
- **Type / Role:** `n8n-nodes-base.gmail` — sends email with attachment.
- **Key configuration:**
  - **To:** `user@example.com` (placeholder)
  - **Subject:** “Market Research Output”
  - **Message:** “Here is the requested doc”
  - **Attachments:** expects binary attachment data (configured via `attachmentsBinary`)
- **Connections:**
  - **Input ←** Documentero
  - No outputs used.
- **Failure/edge cases:**
  - Gmail OAuth2 credentials missing/expired.
  - Attachment mapping risk: node expects binary property name(s). The current configuration shows an empty attachment entry (`attachmentsBinary:[{}]`), which often requires selecting the exact binary field produced by Documentero (e.g., `data` or `file`). If not set, email may send without attachments or fail validation.

**Sticky note (applies to this block):**  
“## Document Generation & Delivery … converted into a document and delivered via email … operationalised into real PM workflows.”

---

## 3. Summary Table

| Node Name | Node Type | Functional Role | Input Node(s) | Output Node(s) | Sticky Note |
|---|---|---|---|---|---|
| When chat message received | LangChain Chat Trigger | Entry point: accept user research idea via chat | — | Planner Agent | ## User Input & Trigger\n\nThis section captures the research topic or product idea provided by the user.\nThe workflow is triggered manually via a chat message to make it easy to test and iterate during discovery. |
| Simple Memory | Memory Buffer Window | Memory context for planner | — | Planner Agent (ai_memory) | ## Research Planning (Planner Agent)\n\nThe planner agent defines the scope of market research before any analysis begins.\nIt translates the user’s idea into clear research tasks and assumptions, ensuring that downstream agents work with structured and consistent inputs. |
| Groq Chat Model1 | Groq Chat Model | LLM for Planner Agent | — | Planner Agent (ai_languageModel) | ## Research Planning (Planner Agent)\n\nThe planner agent defines the scope of market research before any analysis begins.\nIt translates the user’s idea into clear research tasks and assumptions, ensuring that downstream agents work with structured and consistent inputs. |
| Structured Output Parser1 | Structured Output Parser | Enforce planner JSON schema | — | Planner Agent (ai_outputParser) | ## Research Planning (Planner Agent)\n\nThe planner agent defines the scope of market research before any analysis begins.\nIt translates the user’s idea into clear research tasks and assumptions, ensuring that downstream agents work with structured and consistent inputs. |
| Planner Agent | LangChain Agent | Plan research tasks + assumptions; fan-out to specialists | When chat message received | Customer Insights Agent; Market Scan Agent; Competitor Insights Agent | ## Research Planning (Planner Agent)\n\nThe planner agent defines the scope of market research before any analysis begins.\nIt translates the user’s idea into clear research tasks and assumptions, ensuring that downstream agents work with structured and consistent inputs. |
| Simple Memory1 | Memory Buffer Window | Memory for customer research agent | — | Customer Insights Agent (ai_memory) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Groq Chat Model2 | Groq Chat Model | LLM for customer agent | — | Customer Insights Agent (ai_languageModel) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Structured Output Parser2 | Structured Output Parser | Enforce customer insights JSON schema | — | Customer Insights Agent (ai_outputParser) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Customer Insights Agent | LangChain Agent | Infer customer segments/problems/solutions/JTBD | Planner Agent | Merge | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Simple Memory2 | Memory Buffer Window | Memory for market scan agent | — | Market Scan Agent (ai_memory) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Groq Chat Model3 | Groq Chat Model | LLM for market scan agent | — | Market Scan Agent (ai_languageModel) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Structured Output Parser3 | Structured Output Parser | Enforce market scan JSON schema (TAM/SAM/SOM etc.) | — | Market Scan Agent (ai_outputParser) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Market Scan Agent | LangChain Agent | Market sizing + macro/micro trends | Planner Agent | Merge | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Simple Memory3 | Memory Buffer Window | Memory for competitor agent | — | Competitor Insights Agent (ai_memory) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Groq Chat Model4 | Groq Chat Model | LLM for competitor agent | — | Competitor Insights Agent (ai_languageModel) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Structured Output Parser4 | Structured Output Parser | Enforce competitor JSON schema | — | Competitor Insights Agent (ai_outputParser) | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Competitor Insights Agent | LangChain Agent | Competitor/substitute mapping + gaps/patterns | Planner Agent | Merge | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |
| Merge | Merge | Fan-in of 3 parallel agent outputs | Customer Insights Agent; Market Scan Agent; Competitor Insights Agent | Synthesis Agent | ## Insight Synthesis & Decision Memo\n\nOutputs from all research agents are consolidated and analysed in this section.\nThe synthesis agent focuses on producing a decision-ready discovery memo rather than raw AI output, highlighting key insights, risks, and next steps. |
| OpenAI Chat Model3 | OpenAI Chat Model | LLM for final synthesis | — | Synthesis Agent (ai_languageModel) | ## Insight Synthesis & Decision Memo\n\nOutputs from all research agents are consolidated and analysed in this section.\nThe synthesis agent focuses on producing a decision-ready discovery memo rather than raw AI output, highlighting key insights, risks, and next steps. |
| Simple Memory4 | Memory Buffer Window | Memory for synthesis agent | — | Synthesis Agent (ai_memory) | ## Insight Synthesis & Decision Memo\n\nOutputs from all research agents are consolidated and analysed in this section.\nThe synthesis agent focuses on producing a decision-ready discovery memo rather than raw AI output, highlighting key insights, risks, and next steps. |
| Synthesis Agent | LangChain Agent | Convert 3 research outputs into one decision memo JSON | Merge | Format Data for Documentero | ## Insight Synthesis & Decision Memo\n\nOutputs from all research agents are consolidated and analysed in this section.\nThe synthesis agent focuses on producing a decision-ready discovery memo rather than raw AI output, highlighting key insights, risks, and next steps. |
| Format Data for Documentero | Code | Convert memo JSON into ordered HTML sections | Synthesis Agent | Documentero | ## Document Generation & Delivery\n\nThe final discovery memo is converted into a document and delivered via email.\nThis step demonstrates how AI-generated insights can be operationalised into real PM or strategy workflows. |
| Documentero | Documentero | Generate document (and possibly email) from HTML payload | Format Data for Documentero | Send a message | ## Document Generation & Delivery\n\nThe final discovery memo is converted into a document and delivered via email.\nThis step demonstrates how AI-generated insights can be operationalised into real PM or strategy workflows. |
| Send a message | Gmail | Email final document as attachment | Documentero | — | ## Document Generation & Delivery\n\nThe final discovery memo is converted into a document and delivered via email.\nThis step demonstrates how AI-generated insights can be operationalised into real PM or strategy workflows. |
| Sticky Note | Sticky Note | Documentation (no runtime effect) | — | — | ## Description\nThis n8n template demonstrates how to build an AI-powered Market Research Assistant using a multi-agent workflow.\nIt helps you get a 360-degree view of a product idea or research topic by analysing:\n* Customer insights and pain points\n* Market size and macro/micro-economic trends\n* Competitive landscape and alternatives\nThe workflow mirrors how product managers and strategy teams conduct discovery — by breaking down research into parallel workstreams and then synthesizing insights into a single narrative.\n\n\n## How it works\n1. Planner Agent The main agent receives your research topic as input and defines:\n    * Research objective\n    * Key areas of focus (Customer, Market, Competition)\n    * Assumptions and constraints\n2. Parallel Research Agents Based on the planner’s output, three specialist agents run in parallel:\n    * Customer Insights Agent Researches public sources such as articles and forums to infer customer behaviour, pain points, and existing tools.\n    * Market Scan Agent Analyses macro-economic and micro-economic trends, estimates TAM/SAM/SOM, and highlights key risks and assumptions.\n    * Competitor Insights Agent Identifies existing competitors and substitutes and summarises how they are positioned in the market.\n3. Synthesis Agent The outputs from all research agents are consolidated and analysed by a synthesis agent, which produces a market discovery memo.\n4. Final Output The discovery memo is generated as a document and sent to your email.\n\n\n## How to use\n* Trigger the workflow via the chat message node.\n* Provide your research topic or product idea, along with optional context such as target market.\n* The workflow runs automatically and delivers a structured discovery memo to your inbox.\n\n\n## Setup Steps\n* API credentials for:\n    * Groq or OpenAI (LLM)\n    * Documentero (document generation)\n* A configured Documentero template\n* Gmail OAuth or email credentials for delivery of memo\n |
| Sticky Note1 | Sticky Note | Documentation (no runtime effect) | — | — | ## User Input & Trigger\n\nThis section captures the research topic or product idea provided by the user.\nThe workflow is triggered manually via a chat message to make it easy to test and iterate during discovery. |
| Sticky Note2 | Sticky Note | Documentation (no runtime effect) | — | — | ## Research Planning (Planner Agent)\n\nThe planner agent defines the scope of market research before any analysis begins.\nIt translates the user’s idea into clear research tasks and assumptions, ensuring that downstream agents work with structured and consistent inputs. |
| Sticky Note3 | Sticky Note | Documentation (no runtime effect) | — | — | ## Insight Synthesis & Decision Memo\n\nOutputs from all research agents are consolidated and analysed in this section.\nThe synthesis agent focuses on producing a decision-ready discovery memo rather than raw AI output, highlighting key insights, risks, and next steps. |
| Sticky Note4 | Sticky Note | Documentation (no runtime effect) | — | — | ## Document Generation & Delivery\n\nThe final discovery memo is converted into a document and delivered via email.\nThis step demonstrates how AI-generated insights can be operationalised into real PM or strategy workflows. |
| Sticky Note7 | Sticky Note | Documentation (no runtime effect) | — | — | ## Parallel Market Research Agents\n\nThis section runs specialist research agents in parallel to reduce latency and avoid unnecessary dependencies.\nEach agent focuses on a single dimension of discovery (market, customers, or competitors) and works independently based on the planner’s instructions. |

---

## 4. Reproducing the Workflow from Scratch

1) **Create Trigger**
1. Add node: **When chat message received** (`LangChain Chat Trigger`)
2. Set **Response Mode** to **Last Node**.

2) **Create Planner block**
3. Add node: **Groq Chat Model** (rename to **Groq Chat Model1**)
   - Select model: `qwen/qwen3-32b`
   - Configure **Groq credentials** (API key).
4. Add node: **Simple Memory** (`Memory Buffer Window`) for planner.
5. Add node: **Structured Output Parser** (rename **Structured Output Parser1**)
   - Provide JSON schema example with keys:
     - `research_idea`, `research_objective`, `market_task`, `competitor_task`, `customer_task`, `assumptions`
6. Add node: **Agent** (rename **Planner Agent**)
   - Prompt Type: **Define**
   - Paste the planner prompt content; ensure it references `{{$json.chatInput}}`.
   - Add System Message (planning + delegation emphasis).
   - Enable/attach:
     - **Language Model:** connect **Groq Chat Model1** to Planner Agent `ai_languageModel`
     - **Memory:** connect **Simple Memory** to Planner Agent `ai_memory`
     - **Output Parser:** connect **Structured Output Parser1** to Planner Agent `ai_outputParser`
7. Connect: **When chat message received → Planner Agent**.

3) **Create Customer Insights sub-stream**
8. Add **Groq Chat Model** (rename **Groq Chat Model2**) with model `moonshotai/kimi-k2-instruct-0905`.
9. Add **Simple Memory1**.
10. Add **Structured Output Parser2** with schema:
   - `customer_insights.target_customer_segments[]`, `core_problems_ranked[]`, `current_solutions_and_frustrations[]`, `jtbd_insight_statements[]`
11. Add **Customer Insights Agent**
   - Prompt references:
     - `{{$json.output.research_idea}}`
     - `{{$json.output.assumptions}}`
     - `{{$json.output.customer_task}}`
   - Connect:
     - Memory1 → `ai_memory`
     - Groq Chat Model2 → `ai_languageModel`
     - Structured Output Parser2 → `ai_outputParser`
12. Connect: **Planner Agent → Customer Insights Agent**.

4) **Create Market Scan sub-stream**
13. Add **Groq Chat Model3** with model `meta-llama/llama-4-maverick-17b-128e-instruct`.
14. Add **Simple Memory2**.
15. Add **Structured Output Parser3** with the provided “market_definition / tam_sam_som / analyses / risks” schema (manual schema).
16. Add **Market Scan Agent**
   - Prompt references planner fields:
     - `{{$json.output.research_objective}}`, `{{$json.output.market_task}}`, `{{$json.output.research_idea}}`, `{{$json.output.assumptions}}`
   - Connect Memory2, Groq Model3, Parser3 to the agent.
17. Connect: **Planner Agent → Market Scan Agent**.

5) **Create Competitor sub-stream**
18. Add **Groq Chat Model4** with model `moonshotai/kimi-k2-instruct-0905`.
19. Add **Simple Memory3**.
20. Add **Structured Output Parser4** with competitor table + gaps + patterns schema.
21. Add **Competitor Insights Agent**
   - Prompt references:
     - `{{$json.output.research_idea}}`, `{{$json.output.competitor_task}}`, `{{$json.output.assumptions}}`
   - Connect Memory3, Groq Model4, Parser4.
22. Connect: **Planner Agent → Competitor Insights Agent**.

6) **Merge the parallel outputs**
23. Add node: **Merge**
   - Set **Number of inputs** = **3**
24. Connect:
   - Customer Insights Agent → Merge (Input 1 / index 0)
   - Market Scan Agent → Merge (Input 2 / index 1)
   - Competitor Insights Agent → Merge (Input 3 / index 2)

7) **Synthesis**
25. Add node: **OpenAI Chat Model** (rename **OpenAI Chat Model3**)
   - Model: `gpt-4.1-mini`
   - Configure **OpenAI credentials**.
26. Add node: **Simple Memory4**
27. Add node: **Synthesis Agent**
   - Paste the synthesis prompt requiring a single JSON object with the 6 memo sections.
   - (Optional but matching JSON) Enable batching: batch size 3, delay 10s.
   - Connect:
     - OpenAI Chat Model3 → Synthesis Agent `ai_languageModel`
     - Simple Memory4 → Synthesis Agent `ai_memory`
28. Connect: **Merge → Synthesis Agent**.

8) **Format for Documentero**
29. Add node: **Code** (rename **Format Data for Documentero**)
   - Paste the JS that:
     - Reads `$input.first().json.output`
     - Parses if string
     - Builds ordered HTML sections
     - Outputs `research_content_html`, `title`, `generated_date`
30. Connect: **Synthesis Agent → Format Data for Documentero**.

9) **Document generation**
31. Add node: **Documentero**
   - Operation: **Generate and Email** (`generateAndEmail`)
   - Configure **Documentero credentials** and ensure you have a **Documentero template** that expects fields matching what you send (notably `research_content_html`, and any other template variables).
32. Connect: **Format Data for Documentero → Documentero**.

10) **Email delivery via Gmail**
33. Add node: **Gmail → Send a message**
   - Configure Gmail OAuth2 credentials.
   - Set:
     - To: your recipient (replace `user@example.com`)
     - Subject/body as desired
   - Configure **Attachment** to use the binary file output from Documentero (select the exact binary property produced by the Documentero node).
34. Connect: **Documentero → Send a message**.

---

## 5. General Notes & Resources

| Note Content | Context or Link |
|---|---|
| Le texte fourni provient exclusivement d’un workflow automatisé réalisé avec n8n, un outil d’intégration et d’automatisation. Ce traitement respecte strictement les politiques de contenu en vigueur et ne contient aucun élément illégal, offensant ou protégé. Toutes les données manipulées sont légales et publiques. | Compliance / provenance disclaimer (provided by user) |
| This template demonstrates a multi-agent market research assistant (Planner → 3 parallel agents → Synthesis → Document → Email). | From “Description” sticky note |
| Setup requires credentials for Groq/OpenAI, Documentero template + credentials, and Gmail OAuth/email credentials. | From “Description” sticky note |

