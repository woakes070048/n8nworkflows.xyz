Verify AI draft answers with Pearl Hybrid Intelligence and OpenAI

https://n8nworkflows.xyz/workflows/verify-ai-draft-answers-with-pearl-hybrid-intelligence-and-openai-12725


# Verify AI draft answers with Pearl Hybrid Intelligence and OpenAI

## 1. Workflow Overview

**Purpose:** This workflow exposes a webhook endpoint that accepts a chat-style conversation (`messages`) and returns either (a) one targeted clarifying question or (b) a **draft answer generated by OpenAI** that is then **professionally verified by a licensed Pearl expert** via Pearl’s MCP server, returning the verified answer with expert attribution.

**Primary use cases:**
- High-stakes Q&A (notably **legal** and **health**) where an AI draft should be **reviewed/verified by a qualified human expert**.
- Building “hybrid intelligence” assistants that ask **at most one** follow-up question before answering.

### 1.1 Input Reception & Prompt Preparation
Receives a POST request containing `messages`, validates structure, and creates two prompt variants:
- **Clarification gate**: forces model to output either `END` or **one** clarifying question.
- **Draft answer**: produces a structured draft answer with safety framing.

### 1.2 Clarification Gate (OpenAI)
Calls OpenAI Chat Completions with temperature 0 and checks whether the model returned `END`.

### 1.3 Branching Response
- If clarification is needed: respond immediately with `status=needs_clarification`.
- Otherwise: proceed to drafting.

### 1.4 Draft + Pearl Expert Verification
Generates a draft answer with OpenAI, then submits it to Pearl MCP `verifyAnswer` tool for expert verification, and returns `status=verified` including expert identity/expertise when available.

---

## 2. Block-by-Block Analysis

### Block 1 — Intake & Prompt Setup
**Overview:** Accepts webhook payload, validates the `messages` array, normalizes it, and constructs two message arrays for the OpenAI clarification step and the draft step.

**Nodes involved:**
- **Pearl Verify Webhook**
- **Prepare Input**

#### Node: Pearl Verify Webhook
- **Type / Role:** `Webhook` — entry point HTTP endpoint.
- **Configuration choices:**
  - **Path:** `pearl-verify`
  - **Method:** `POST`
  - **Response mode:** `responseNode` (workflow must end in a Respond to Webhook node on all branches).
- **Inputs/Outputs:**
  - **Output →** `Prepare Input`
- **Potential failures / edge cases:**
  - Calling with wrong HTTP method/path returns 404/405.
  - If caller expects immediate response but execution errors occur before a Respond node, request may time out.
- **Version-specific notes:** Uses Webhook node v2.1 (supports responseMode settings as configured).

#### Node: Prepare Input
- **Type / Role:** `Code` — input validation + prompt building.
- **Configuration choices (interpreted):**
  - Expects incoming payload to include **`messages`** in either:
    - `items[0].json.body.messages` (typical Webhook body), or
    - `items[0].json.messages` (fallback).
  - Default OpenAI model: **`gpt-4o-mini`** if `body.model` not provided.
  - Validates each message:
    - must be an object
    - `role` non-empty string
    - `content` non-empty string
  - Normalizes whitespace in `role` and `content`.
  - Builds:
    - `messagesClarify`: system prompt (intake gate) + conversation
    - `messagesDraft`: system prompt (drafting + safety) + conversation
  - Extracts `userQuestion` as the last user message.
- **Key variables emitted:**
  - `openaiModel`
  - `messages` (normalized)
  - `userQuestion`
  - `messagesClarify`
  - `messagesDraft`
- **Inputs/Outputs:**
  - **Input ←** `Pearl Verify Webhook`
  - **Output →** `OpenAI - Clarify`
- **Potential failures / edge cases:**
  - Missing/invalid `messages` throws an error and stops execution (no webhook response unless error handling is added).
  - Strict requirement that `content` is a non-empty string (fails if caller sends structured content blocks).
  - If conversation has no `user` role message, `userQuestion` becomes `""` (not fatal, but may reduce answer quality).
- **Version-specific notes:** Code node v2.

---

### Block 2 — Intake (Clarification)
**Overview:** Sends the clarification-gate prompt to OpenAI. If the result is not exactly `END`, the workflow returns a single clarifying question.

**Nodes involved:**
- **OpenAI - Clarify**
- **IF - Needs clarification?**
- **Respond: Clarification Question**

#### Node: OpenAI - Clarify
- **Type / Role:** `HTTP Request` — OpenAI Chat Completions call for intake gating.
- **Configuration choices (interpreted):**
  - **POST** `https://api.openai.com/v1/chat/completions`
  - Uses **predefined credential type**: `openAiApi`
  - JSON body:
    - `model`: `{{$json.openaiModel}}` (from Prepare Input)
    - `messages`: `{{$json.messagesClarify}}`
    - `temperature`: `0` (deterministic, consistent gate behavior)
- **Inputs/Outputs:**
  - **Input ←** `Prepare Input`
  - **Output →** `IF - Needs clarification?`
- **Potential failures / edge cases:**
  - OpenAI credential missing/invalid (401/403).
  - Model name invalid (400).
  - Rate limits/timeouts.
  - Response schema differences: this workflow assumes `choices[0].message.content` exists.

#### Node: IF - Needs clarification?
- **Type / Role:** `IF` — branching based on OpenAI output.
- **Configuration choices (interpreted):**
  - Condition: `{{$json.choices[0].message.content.trim()}} != "END"`
  - Strict type validation enabled.
- **Inputs/Outputs:**
  - **Input ←** `OpenAI - Clarify`
  - **True output →** `Respond: Clarification Question` (clarification needed)
  - **False output →** `Open AI - Draft Answer` (ready to draft)
- **Potential failures / edge cases:**
  - If `choices[0].message.content` is missing/null, the expression can error.
  - If model returns `"END."` or `"END\n"` it is trimmed, but punctuation would still fail equality—causing unintended clarification branch.

#### Node: Respond: Clarification Question
- **Type / Role:** `Respond to Webhook` — returns early response.
- **Configuration choices (interpreted):**
  - Responds with JSON:
    - `status: "needs_clarification"`
    - `clarificationQuestion: <trimmed model output>`
- **Inputs/Outputs:**
  - **Input ←** `IF - Needs clarification?` (true branch)
  - Terminates webhook request.
- **Potential failures / edge cases:**
  - If upstream output is malformed, `clarificationQuestion` expression may fail.
- **Version-specific notes:** Respond node v1.5.

---

### Block 3 — Draft + Expert Verification
**Overview:** If no clarification is needed, the workflow drafts an answer with OpenAI and submits it to Pearl MCP’s `verifyAnswer` tool for licensed expert review, returning the verified answer and expert attribution.

**Nodes involved:**
- **Open AI - Draft Answer**
- **MCP Client**
- **Respond: Verified Answer by Pearl Expert**

#### Node: Open AI - Draft Answer
- **Type / Role:** `HTTP Request` — OpenAI Chat Completions for draft generation.
- **Configuration choices (interpreted):**
  - **POST** `https://api.openai.com/v1/chat/completions`
  - Uses OpenAI credentials (`openAiApi`)
  - JSON body:
    - `model`: `{{$node['Prepare Input'].json.openaiModel}}`
    - `messages`: `{{$node['Prepare Input'].json.messagesDraft}}`
    - `temperature`: `0.2` (slightly more generative but still controlled)
- **Inputs/Outputs:**
  - **Input ←** `IF - Needs clarification?` (false branch)
  - **Output →** `MCP Client`
- **Potential failures / edge cases:**
  - Same OpenAI API risks as above (auth, rate limits, invalid model).
  - Assumes `choices[0].message.content` contains the draft text.

#### Node: MCP Client
- **Type / Role:** `@n8n/n8n-nodes-langchain.mcpClient` — calls Pearl MCP server tool to verify the draft.
- **Configuration choices (interpreted):**
  - **Endpoint URL:** `https://mcp.pearl.com/mcp`
  - **Tool selected:** `verifyAnswer`
  - **Authentication:** `headerAuth` (requires Pearl MCP Server API key in headers via credential)
  - **Input mode:** JSON
  - JSON input payload:
    - `answer`: `{{$json.choices[0].message.content.trim()}}` (draft from OpenAI)
    - `chatHistory`: `{{$('Prepare Input').item.json.messages}}` (normalized conversation)
- **Inputs/Outputs:**
  - **Input ←** `Open AI - Draft Answer`
  - **Output →** `Respond: Verified Answer by Pearl Expert`
- **Potential failures / edge cases:**
  - Missing/invalid Pearl API key → 401/403.
  - Tool name mismatch or server-side contract changes.
  - Response schema assumptions downstream (`content[0].text.answer`, `expert` fields).
  - Network timeouts to Pearl MCP endpoint.
- **Version-specific notes:** Node typeVersion 1; requires the LangChain MCP client node package available in the n8n instance.

#### Node: Respond: Verified Answer by Pearl Expert
- **Type / Role:** `Respond to Webhook` — returns final verified answer.
- **Configuration choices (interpreted):**
  - Responds with JSON:
    - `status: "verified"`
    - `answer: $json.content[0].text.answer`
    - `verifiedBy`: concatenation of expert `name` and `expertise` if present
      - Uses optional chaining and filters empty values.
- **Inputs/Outputs:**
  - **Input ←** `MCP Client`
  - Terminates webhook request.
- **Potential failures / edge cases:**
  - If Pearl response doesn’t include `content[0].text.answer`, expression may error or return undefined.
  - Expert attribution may be blank if fields absent (handled by filtering).

---

## 3. Summary Table

| Node Name | Node Type | Functional Role | Input Node(s) | Output Node(s) | Sticky Note |
|---|---|---|---|---|---|
| Overview | Sticky Note | Documentation / workflow description | — | — | # Verify AI answers with Pearl Hybrid Intelligence and Open AI; How it works; Setup steps; Demo key link: https://www.pearl.com/enterprise/contact-get-started |
| Pearl Verify Webhook | Webhook | Receives conversation via POST and starts workflow | — | Prepare Input | ## 1) Intake & prompt setup; Receives the user conversation and prepares prompts for intake + drafting. |
| Prepare Input | Code | Validates input and builds clarification + draft prompts | Pearl Verify Webhook | OpenAI - Clarify | ## 1) Intake & prompt setup; Receives the user conversation and prepares prompts for intake + drafting. |
| OpenAI - Clarify | HTTP Request | Calls OpenAI to decide END vs single clarifying question | Prepare Input | IF - Needs clarification? | ## 2) Intake (clarification); Asks one follow-up question if more information is needed. |
| IF - Needs clarification? | IF | Branches on whether response != END | OpenAI - Clarify | Respond: Clarification Question; Open AI - Draft Answer | ## 2) Intake (clarification); Asks one follow-up question if more information is needed. |
| Respond: Clarification Question | Respond to Webhook | Returns `needs_clarification` and question | IF - Needs clarification? (true) | — | ## 2) Intake (clarification); Asks one follow-up question if more information is needed. |
| Open AI - Draft Answer | HTTP Request | Generates draft answer with OpenAI | IF - Needs clarification? (false) | MCP Client | ## 3) Draft + expert verification; Drafts an answer, then sends it to Pearl for professional verification. |
| MCP Client | MCP Client (LangChain) | Sends draft + chat history to Pearl for expert verification | Open AI - Draft Answer | Respond: Verified Answer by Pearl Expert | ## 3) Draft + expert verification; Drafts an answer, then sends it to Pearl for professional verification. |
| Respond: Verified Answer by Pearl Expert | Respond to Webhook | Returns verified answer + expert attribution | MCP Client | — | ## 3) Draft + expert verification; Drafts an answer, then sends it to Pearl for professional verification. |
| Sticky Note | Sticky Note | Section label for block 1 | — | — | ## 1) Intake & prompt setup; Receives the user conversation and prepares prompts for intake + drafting. |
| Sticky Note1 | Sticky Note | Section label for block 2 | — | — | ## 2) Intake (clarification); Asks one follow-up question if more information is needed. |
| Sticky Note2 | Sticky Note | Section label for block 3 | — | — | ## 3) Draft + expert verification; Drafts an answer, then sends it to Pearl for professional verification. |

---

## 4. Reproducing the Workflow from Scratch

1) **Create a new workflow**
   - Name: **Verify AI draft answers with Pearl Hybrid Intelligence and Open AI**
   - Keep it inactive until credentials are set.

2) **Add Webhook node**
   - Node type: **Webhook**
   - Name: **Pearl Verify Webhook**
   - HTTP Method: **POST**
   - Path: **pearl-verify**
   - Response Mode: **Using “Respond to Webhook” node** (responseNode)

3) **Add Code node**
   - Node type: **Code**
   - Name: **Prepare Input**
   - Paste logic that:
     - Reads request body (prefer `items[0].json.body`, fallback to `items[0].json`)
     - Requires `body.messages` (array of `{role, content}`)
     - Sets default model `gpt-4o-mini` from `body.model` if provided
     - Produces `messagesClarify` and `messagesDraft` arrays (system + conversation)
     - Outputs: `openaiModel`, `messages`, `userQuestion`, `messagesClarify`, `messagesDraft`

4) **Connect**: `Pearl Verify Webhook` → `Prepare Input`

5) **Add HTTP Request node for clarification**
   - Node type: **HTTP Request**
   - Name: **OpenAI - Clarify**
   - Method: **POST**
   - URL: `https://api.openai.com/v1/chat/completions`
   - Authentication: **Predefined Credential Type**
   - Credential type: **OpenAI API (`openAiApi`)**
   - Body type: **JSON**
   - Send body: **true**
   - JSON body expression:
     - `model`: `{{$json.openaiModel}}`
     - `messages`: `{{$json.messagesClarify}}`
     - `temperature`: `0`

6) **Connect**: `Prepare Input` → `OpenAI - Clarify`

7) **Add IF node**
   - Node type: **IF**
   - Name: **IF - Needs clarification?**
   - Condition (string):
     - Left: `{{$json.choices[0].message.content.trim()}}`
     - Operation: **not equals**
     - Right: `END`

8) **Connect**: `OpenAI - Clarify` → `IF - Needs clarification?`

9) **Add Respond to Webhook node (clarification branch)**
   - Node type: **Respond to Webhook**
   - Name: **Respond: Clarification Question**
   - Respond with: **JSON**
   - Response body expression:
     - `status`: `needs_clarification`
     - `clarificationQuestion`: `{{$json.choices[0].message.content.trim()}}`

10) **Connect** IF true output → `Respond: Clarification Question`

11) **Add HTTP Request node for drafting**
   - Node type: **HTTP Request**
   - Name: **Open AI - Draft Answer**
   - Method: **POST**
   - URL: `https://api.openai.com/v1/chat/completions`
   - Authentication: **OpenAI API (`openAiApi`)**
   - JSON body expression:
     - `model`: `{{$node['Prepare Input'].json.openaiModel}}`
     - `messages`: `{{$node['Prepare Input'].json.messagesDraft}}`
     - `temperature`: `0.2`

12) **Connect** IF false output → `Open AI - Draft Answer`

13) **Add MCP Client node (Pearl verification)**
   - Node type: **MCP Client** (`@n8n/n8n-nodes-langchain.mcpClient`)
   - Name: **MCP Client**
   - Endpoint URL: `https://mcp.pearl.com/mcp`
   - Authentication: **Header Auth**
     - Create/configure a credential that sends Pearl MCP API key in header (per Pearl’s requirement).
   - Tool: **verifyAnswer**
   - Input mode: **JSON**
   - JSON input expression:
     - `answer`: `{{$json.choices[0].message.content.trim()}}`
     - `chatHistory`: `{{$('Prepare Input').item.json.messages}}`

14) **Connect**: `Open AI - Draft Answer` → `MCP Client`

15) **Add Respond to Webhook node (verified branch)**
   - Node type: **Respond to Webhook**
   - Name: **Respond: Verified Answer by Pearl Expert**
   - Respond with: **JSON**
   - Response body expression:
     - `status`: `verified`
     - `answer`: `{{$json.content[0].text.answer}}`
     - `verifiedBy`: join of:
       - `{{$json.content?.[0]?.text?.expert?.name}}`
       - `{{$json.content?.[0]?.text?.expert?.expertise}}`
       filtered for non-empty values

16) **Connect**: `MCP Client` → `Respond: Verified Answer by Pearl Expert`

17) **Credentials setup**
   - **OpenAI credential (openAiApi):**
     - Configure API key in n8n credentials.
     - Ensure the account has access to the model you set (default `gpt-4o-mini`).
   - **Pearl MCP header auth credential:**
     - Add the API key header as required by Pearl MCP server.
     - Demo key request link (from workflow note): https://www.pearl.com/enterprise/contact-get-started

18) **Activate and test**
   - Call the webhook URL with JSON body:
     - `messages`: array of `{role, content}`
     - optionally `model`
   - Ensure both branches return responses (clarification vs verified).

---

## 5. General Notes & Resources

| Note Content | Context or Link |
|---|---|
| Request a demo Pearl MCP Server API key | https://www.pearl.com/enterprise/contact-get-started |
| Workflow behavior summary: asks at most one clarifying question; drafts with OpenAI; verified by licensed Pearl expert; returns verified answer with attribution | Embedded in the “Overview” sticky note |
| Prompt customization guidance: adjust intake + drafting prompts in **Prepare Input** to match domain and tone | Embedded in the “Overview” sticky note |